{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D\n",
    "from keras.models import Sequential,Model\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Bidirectional,TimeDistributed\n",
    "import numpy as np\n",
    "import codecs\n",
    "import regex\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_div=1\n",
    "sent=[]\n",
    "tags=[]\n",
    "with codecs.open(\"v1_train.ml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in f:\n",
    "        x=i.split()\n",
    "        if(x[0]==\"newline\"):\n",
    "            sent.append(l1)\n",
    "            tags.append(l2)\n",
    "            l1=[]\n",
    "            l2=[]\n",
    "        else:\n",
    "            l1.append(x[0])\n",
    "            l2.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65188\n",
      "136669\n",
      "{'name': 59422, 'organization': 4841, 'location': 29371, 'other': 701664, 'things': 1999, 'datenum': 1609, 'event': 837, 'occupation': 8037, 'number': 30553}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(sent))\n",
    "tag_count=0\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        if(j!=\"other\"):\n",
    "            tag_count+=1\n",
    "print(tag_count)\n",
    "tag_map={'datenum': 0,\n",
    " 'event': 0,\n",
    " 'location': 0,\n",
    " 'name': 0,\n",
    " 'number': 0,\n",
    " 'occupation': 0,\n",
    " 'organization': 0,\n",
    " 'other': 0,\n",
    " 'things': 0}\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        tag_map[j]+=1\n",
    "print(tag_map)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagar/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sagar/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58669\n",
      "58669\n",
      "6519\n",
      "6519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sent,pre_x_test,tags,pre_y_test=train_test_split(sent,tags,test_size=0.1,random_state=1)\n",
    "print(len(sent))\n",
    "print(len(tags))\n",
    "print(len(pre_x_test))\n",
    "print(len(pre_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 15293\n",
      "1 : 14475\n",
      "2 : 10700\n",
      "3 : 6680\n",
      "4 : 4277\n",
      "5 : 2624\n",
      "6 : 1589\n",
      "7 : 1086\n",
      "8 : 670\n",
      "9 : 439\n",
      "10 : 302\n",
      "11 : 180\n",
      "12 : 109\n",
      "13 : 60\n",
      "14 : 50\n",
      "15 : 39\n",
      "16 : 22\n",
      "17 : 13\n",
      "18 : 13\n",
      "19 : 14\n",
      "20 : 5\n",
      "21 : 6\n",
      "22 : 3\n",
      "23 : 6\n",
      "24 : 2\n",
      "26 : 1\n",
      "27 : 2\n",
      "29 : 1\n",
      "31 : 1\n",
      "33 : 2\n",
      "34 : 3\n",
      "62 : 1\n",
      "123 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_distribution(sent,tags):\n",
    "    cnt_dict={}\n",
    "    for i in tags:\n",
    "        cnt=0\n",
    "        for j in i:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in cnt_dict):\n",
    "            cnt_dict[cnt]+=1\n",
    "        else:\n",
    "            cnt_dict[cnt]=1\n",
    "    cnt_list=list(cnt_dict.keys())\n",
    "    cnt_list.sort()\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in cnt_list:\n",
    "        print(i,\":\",cnt_dict[i])\n",
    "        l1.append(i)\n",
    "        l2.append(cnt_dict[i])\n",
    "    plt.plot(l1,l2)\n",
    "    plt.xlabel(\"no. of non-other tags in the sentence\")\n",
    "    plt.ylabel(\"no. of sentences\")\n",
    "    plt.show()\n",
    "get_data_distribution(sent,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58669\n",
      "58669\n"
     ]
    }
   ],
   "source": [
    "def filter_data(sent,tags,exclude_list):\n",
    "    sent_filter=[]\n",
    "    tags_filter=[]\n",
    "    for i in range(len(tags)):\n",
    "    #     print(tags[i])\n",
    "        cnt=0\n",
    "        for j in tags[i]:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in exclude_list):\n",
    "            continue\n",
    "        if(cnt>=0):\n",
    "            sent_filter.append(sent[i])\n",
    "            tags_filter.append(tags[i])\n",
    "    return sent_filter,tags_filter\n",
    "sent_filter,tags_filter=filter_data(sent,tags,[])\n",
    "print(len(sent_filter))\n",
    "print(len(tags_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_len= 58669\n",
      "new_len= 58669\n"
     ]
    }
   ],
   "source": [
    "sent=sent_filter\n",
    "tags=tags_filter\n",
    "def divide_data_pactise(sent,tags,data_div):\n",
    "    print(\"initial_len=\",len(sent))\n",
    "    sent=sent[:len(sent)//data_div]\n",
    "    tags=tags[:len(tags)//data_div]\n",
    "    return sent,tags\n",
    "sent,tags=divide_data_pactise(sent,tags,data_div)\n",
    "print(\"new_len=\",len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['അദ്ദേഹം', 'ജനിച്ചത്', 'തമിഴ്', 'നാട്', 'സംസ്ഥാനത്തിലെ', 'മധുരയില്', 'ആണ്', '.']\n",
      "['ലോകത്തിലെ', 'ഏറ്റവും', 'മഹത്തായ', 'കൃതികളിൽ', 'ഒന്നായി', 'വിശേഷിക്കപ്പെടുന്ന', 'ഒരു', 'സഞ്ചാര', 'നോവൽ', 'ആണ്', 'റോബിൻസൺ', 'ക്രൂസോ', 'ഇംഗ്ലീഷ്', 'പത്ര', 'പ്രവർത്തകനും', 'നോവലിസ്റ്റും', 'ലഘു', 'ലേഖാകാരനും', 'ആയ', 'ഡാനിയൽ', 'ഡീഫോ', 'ആണ്', 'ഈ', 'പ്രശസ്ത', 'ഗ്രന്ഥത്തിന്റെ', 'കർത്താവു', '.']\n",
      "['2012', 'ലെ', 'പശ്ചാത്തലസംഗീതത്തിന്', 'ഉള്ള', 'ദേശീയ', 'ചലച്ചിത്രപുരസ്കാരം', 'നേടിയ', 'സംഗീതസംവിധായകന്', 'ആണ്', 'ബിജിബാൽ', 'ജനനം', '.']\n",
      "['ഗുലാൻ', 'പരിശ്', 'അഥവാ', 'തുറുപ്പുകളി', 'വിഭാഗത്തിൽപ്പെട്ട', 'ഏറ്റവും', 'അടിസ്ഥാനപരം', 'ആയ', 'ചീട്ടുകളി', 'ആണ്', 'ഇരുപത്തിയെട്ട്', '.']\n",
      "['ഒഡിഎഫ്', 'പിൻതുണ', 'ഉള്ള', 'ഒരു', 'കമ്പനി', 'ഇതര', 'സ്വതന്ത്ര', 'ഓഫീസ്', 'പാക്കേജ്', 'നിർമ്മിക്കുക', 'എന്നത്', 'ആണ്', 'ലിബ്രേഓഫീസിന്റെ', 'പ്രധാന', 'ലക്ഷ്യം', '.']\n",
      "['അതിന്റെ', 'പ്രയോഗത്തിലും', 'ഗുണത്തിലും', 'എ', 'എസ്', 'പി', ',', 'പി', 'എച്ച്', 'പി', ',', 'ജെ', 'എസ്', 'പി', '.']\n",
      "['ഭദ്രഭഗവതിയുടെ', 'ഉത്സവചടങ്ങുകളും', ',', 'ഭുവനേശ്വരിയുടെ', 'പൂജാവിധികളും', 'ആയി', 'പരാശക്തിയുടെ', 'വിവിധ', 'ഭാവങ്ങൾ', 'സമന്വയിപ്പിക്കുന്ന', 'ആചാരം', 'ആണ്', 'ഇവിടെ', 'ഉള്ളത്', 'ഋഷഭം', 'ആണ്', 'ഭഗവതിയുടെ', 'വാഹനം', '.']\n",
      "['തൃശ്ശൂർ', 'നഗരത്തിൽ', 'നിന്നും', 'ഏറ്റവും', 'അടുത്ത', 'കടൽത്തീരം', '20', 'കിലോമീറ്റർ', 'അകലെ', 'ഉള്ള', 'വാടാനപ്പള്ളി', 'കടൽത്തീരം', 'ആണ്', '.']\n",
      "['യുദ്ധത്തിൽ', 'മുസ്ലിം', 'സൈന്യം', 'തന്ത്ര', 'പരം', 'ആയി', 'പിന്മാറി', '.']\n",
      "['അമേരിക്കൻ', 'ഐക്യനാടുകളിലെ', 'വടക്കുകിഴക്കൻ', 'തീരത്ത്', 'അറ്റ്ലാന്റിക്', 'മഹാസമുദ്രത്തോടു', 'ചേർന്നു', 'സ്ഥിതിചെയ്യുന്ന', 'സംസ്ഥാനം', 'ആണ്', 'ന്യൂ', 'യോർക്ക്', 'ഏറ്റവും', 'വലിയ', 'നഗരം', 'ന്യൂ', 'യോർക്ക്', 'നഗരവും', 'തലസ്ഥാനം', 'ആൽബനിയും', 'ആണ്', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in sent[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent_len 233\n",
      "avg_sent_len 12.867510951268983\n",
      "max_sent_len_fit 25\n"
     ]
    }
   ],
   "source": [
    "max_sent_len=-1\n",
    "for i in sent:\n",
    "    if(len(i)>max_sent_len):\n",
    "        max_sent_len=len(i)\n",
    "print(\"max_sent_len\",max_sent_len)\n",
    "avg_sent_len=0\n",
    "for i in sent:\n",
    "    avg_sent_len+=len(i)\n",
    "avg_sent_len=avg_sent_len/len(sent)\n",
    "print(\"avg_sent_len\",avg_sent_len)\n",
    "max_len=int(2*(avg_sent_len))\n",
    "print(\"max_sent_len_fit\",max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex.findall(r'\\X', sent[0][0])\n",
    "def separate_into_char(sent):\n",
    "    char=[]\n",
    "    for i in sent:\n",
    "        for j in i:\n",
    "            l=regex.findall(r'\\X',j)\n",
    "            char.append(l)\n",
    "    return char\n",
    "char=separate_into_char(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['അ', 'ദ്', 'ദേ', 'ഹം']\n",
      "['ജ', 'നി', 'ച്', 'ച', 'ത്']\n",
      "['ത', 'മി', 'ഴ്']\n",
      "['നാ', 'ട്']\n",
      "['സം', 'സ്', 'ഥാ', 'ന', 'ത്', 'തി', 'ലെ']\n",
      "['മ', 'ധു', 'ര', 'യി', 'ല്']\n",
      "['ആ', 'ണ്']\n",
      "['.']\n",
      "['ലോ', 'ക', 'ത്', 'തി', 'ലെ']\n",
      "['ഏ', 'റ്', 'റ', 'വും']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in char[:10]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_size=50\n",
    "word_min_count=1\n",
    "c2v=Word2Vec(char,size=char_embedding_size,min_count=word_min_count)\n",
    "# print(c2v.wv[\"ल\"])\n",
    "# c2v.wv.most_similar(positive=\"ा\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2750"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c2v.wv.most_similar(positive=\"क\")\n",
    "len(c2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750\n",
      "2062\n"
     ]
    }
   ],
   "source": [
    "tokenizer_char=Tokenizer()\n",
    "tokenizer_char.fit_on_texts(char)\n",
    "char_index=tokenizer_char.word_index\n",
    "print(len(char_index))\n",
    "num_char=(len(char_index)*3)//4\n",
    "print(num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2063\n",
      "<UNK_CHAR>\n"
     ]
    }
   ],
   "source": [
    "def add_unk_char(char_index,num_char):\n",
    "    ref={}\n",
    "    for i,j in char_index.items():\n",
    "        if(j<=num_char):\n",
    "            ref[i]=j\n",
    "    ref[\"<UNK_CHAR>\"]=num_char+1\n",
    "    char_index=ref\n",
    "    char_index_rev={}\n",
    "    for (i,j) in char_index.items():\n",
    "        char_index_rev[j]=i\n",
    "    print(char_index[\"<UNK_CHAR>\"])\n",
    "    print(char_index_rev[char_index[\"<UNK_CHAR>\"]])\n",
    "    return char_index,char_index_rev\n",
    "char_index,char_index_rev=add_unk_char(char_index,num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of chars: 2063\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of chars:\",len(char_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "4.079837175662716\n",
      "max_char_len_fit 8\n"
     ]
    }
   ],
   "source": [
    "max_char_len=-1\n",
    "for i in char:\n",
    "    if(len(i)>max_char_len):\n",
    "        max_char_len=len(i)\n",
    "print(max_char_len)\n",
    "avg_char_len=0\n",
    "for i in char:\n",
    "    avg_char_len+=len(i)\n",
    "avg_char_len=avg_char_len/len(char)\n",
    "print(avg_char_len)\n",
    "max_char_len=int(2*avg_char_len)\n",
    "print(\"max_char_len_fit\",max_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words: 135262\n",
      "No. of tags: 9\n",
      "101446\n"
     ]
    }
   ],
   "source": [
    "tokenizer_sent=Tokenizer()\n",
    "tokenizer_tags=Tokenizer()\n",
    "tokenizer_sent.fit_on_texts(sent)\n",
    "tokenizer_tags.fit_on_texts(tags)\n",
    "word_index_sent=tokenizer_sent.word_index\n",
    "word_index_tags=tokenizer_tags.word_index\n",
    "print(\"No. of words:\",len(word_index_sent))\n",
    "print(\"No. of tags:\",len(word_index_tags))\n",
    "num_words=(len(word_index_sent)*3)//4\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref={}\n",
    "for i,j in word_index_sent.items():\n",
    "    if(j<=num_words):\n",
    "        ref[i]=j\n",
    "ref[\"<UNK_WORD>\"]=num_words+1\n",
    "word_index_sent=ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_rev_sent={}\n",
    "word_index_rev_tags={}\n",
    "for i,j in word_index_sent.items():\n",
    "    word_index_rev_sent[j]=i\n",
    "for i,j in word_index_tags.items():\n",
    "    word_index_rev_tags[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char={}\n",
    "for i,j in word_index_sent.items():\n",
    "#     print(i,j)\n",
    "    l=[]\n",
    "    if(i==\"<UNK_WORD>\"):\n",
    "        l=[char_index[\"<UNK_CHAR>\"]]*max_char_len\n",
    "        word_char[i]=l\n",
    "#         print(l)\n",
    "        continue\n",
    "    for k in regex.findall(r'\\X',i):\n",
    "        if(k in char_index):\n",
    "#             print(k,end=\"-\")\n",
    "            h=char_index[k]\n",
    "        else:\n",
    "#             print(k)\n",
    "            h=char_index[\"<UNK_CHAR>\"]\n",
    "#         else:\n",
    "#             print(i)\n",
    "#             print(k,end=\"-\")\n",
    "#             h=char_index[\"<UNK_CHAR>\"]\n",
    "#             print(\"********\")\n",
    "#             print(\"------------------------------\")\n",
    "#             #         print(h)\n",
    "        l.append(h)\n",
    "    word_char[i]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char.items():\n",
    "#     print(i)\n",
    "# print(word_char[\"<UNK_WORD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in word_char.items():\n",
    "    word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101447\n",
      "('വിട്ടിട്ടുപോയി', array([ 32,  18,  49,  18,  45, 134,  17,   0], dtype=int32))\n",
      "('ശീതീകരണികൾ', array([244, 199,   4,   6, 118,   4,  44,   0], dtype=int32))\n",
      "('യാക്കോബിന്റെ', array([ 68,   3, 111, 167,   1,  51,   0,   0], dtype=int32))\n",
      "('ടർട്ടിൽ', array([33, 11, 18, 49, 13,  0,  0,  0], dtype=int32))\n",
      "('ആൾ', array([ 5, 44,  0,  0,  0,  0,  0,  0], dtype=int32))\n",
      "('ഒടുങ്ങാത്ത', array([ 52,  45,  29, 343,   2,  21,   0,   0], dtype=int32))\n",
      "('ശബാബിന്റെ', array([ 93, 171, 167,   1,  51,   0,   0,   0], dtype=int32))\n",
      "('പ്രവർത്തന', array([14,  6, 16, 11,  2, 21,  8,  0], dtype=int32))\n",
      "('പരിചയപ്പെട്ട', array([20, 31, 59,  7, 14, 74, 18, 33], dtype=int32))\n",
      "('ജെന്ന', array([292,   1,   8,   0,   0,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_char={}\n",
    "# for i,j in word_index_sent.items():\n",
    "#     l=[]\n",
    "#     for k in regex.findall(r'\\X',i):\n",
    "#         if(k in char_index):\n",
    "#             l.append(char_index[k])\n",
    "#         else:\n",
    "#             l.append(char_index[\"<UNK_CHAR>\"])\n",
    "#     word_char[i]=l\n",
    "# for i,j in word_char.items():\n",
    "#     word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101447\n",
      "('വിട്ടിട്ടുപോയി', array([ 32,  18,  49,  18,  45, 134,  17,   0], dtype=int32))\n",
      "('ശീതീകരണികൾ', array([244, 199,   4,   6, 118,   4,  44,   0], dtype=int32))\n",
      "('യാക്കോബിന്റെ', array([ 68,   3, 111, 167,   1,  51,   0,   0], dtype=int32))\n",
      "('ടർട്ടിൽ', array([33, 11, 18, 49, 13,  0,  0,  0], dtype=int32))\n",
      "('ആൾ', array([ 5, 44,  0,  0,  0,  0,  0,  0], dtype=int32))\n",
      "('ഒടുങ്ങാത്ത', array([ 52,  45,  29, 343,   2,  21,   0,   0], dtype=int32))\n",
      "('ശബാബിന്റെ', array([ 93, 171, 167,   1,  51,   0,   0,   0], dtype=int32))\n",
      "('പ്രവർത്തന', array([14,  6, 16, 11,  2, 21,  8,  0], dtype=int32))\n",
      "('പരിചയപ്പെട്ട', array([20, 31, 59,  7, 14, 74, 18, 33], dtype=int32))\n",
      "('ജെന്ന', array([292,   1,   8,   0,   0,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_int={}\n",
    "for i,j in word_char.items():\n",
    "    word_char_int[word_index_sent[i]]=j\n",
    "# for i in word_char_int.items():\n",
    "#     print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_embedding_matrix=np.zeros((len(word_char) + 1, max_char_len))\n",
    "for i,j in word_char_int.items():\n",
    "    word_char_embedding_matrix[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char_embedding_matrix:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101448, 50)\n"
     ]
    }
   ],
   "source": [
    "char_embedding_matrix = np.zeros((len(word_char) + 1, char_embedding_size))\n",
    "for i,j in char_index_rev.items():\n",
    "    if(j in c2v.wv.vocab):\n",
    "        char_embedding_matrix[i]=c2v.wv[j]\n",
    "print(char_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in char_embedding_matrix:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_int=[]\n",
    "for i in word_char_int.items():\n",
    "    char_int.append(i[1])\n",
    "# print(char_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datenum': 8,\n",
       " 'event': 9,\n",
       " 'location': 4,\n",
       " 'name': 2,\n",
       " 'number': 3,\n",
       " 'occupation': 5,\n",
       " 'organization': 6,\n",
       " 'other': 1,\n",
       " 'things': 7}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK_WORD>\n"
     ]
    }
   ],
   "source": [
    "# word_char[\"<UNK_WORD>\"]#array([2389, 2389, 2389, 2389, 2389], dtype=int32)\n",
    "# word_index_sent[\"<UNK_WORD>\"]#2389\n",
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j==\"<UNK_WORD>\"):\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int=[]\n",
    "for i in sent:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    sent_int.append(l)\n",
    "tags_int=[]\n",
    "for i in tags:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        l.append(word_index_tags[j])\n",
    "    tags_int.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int_padded=pad_sequences(sent_int,maxlen=max_len,padding='post')\n",
    "tags_int_padded=pad_sequences(tags_int,maxlen=max_len,padding=\"post\")\n",
    "# for i in tags_int_padded:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=100\n",
    "workers=5\n",
    "window_size=5\n",
    "word_min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sent:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101448, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v=Word2Vec(sent,size=embedding_size,workers=workers,window=window_size,min_count=word_min_count)\n",
    "embedding_matrix = np.zeros((len(word_index_sent) + 1, embedding_size))\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-2.02617431  0.50198776 -1.09247422 ...  0.35541478  0.01099015\n",
      "   0.12722921]\n",
      " [-0.35879561 -0.41089478 -0.70554143 ... -0.3978056   0.02952287\n",
      "   0.39583072]\n",
      " ...\n",
      " [-0.00810405 -0.00530671 -0.01091699 ... -0.00604393 -0.00477821\n",
      "   0.00501169]\n",
      " [-0.0136035  -0.00451232 -0.00716436 ... -0.00385177 -0.00605906\n",
      "   0.00518115]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j in w2v.wv.vocab):\n",
    "        embedding_matrix[i]=w2v.wv[j]\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('datenum', 8)\n",
      "('event', 9)\n",
      "('occupation', 5)\n",
      "('name', 2)\n",
      "('other', 1)\n",
      "('number', 3)\n",
      "('location', 4)\n",
      "('organization', 6)\n",
      "('things', 7)\n",
      "{'datenum': array([0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'event': array([0., 0., 0., 0., 0., 0., 0., 0., 1.]), 'occupation': array([0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'name': array([0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'other': array([1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'number': array([0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'location': array([0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'organization': array([0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'things': array([0., 0., 0., 0., 0., 0., 1., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "tag_dir={}\n",
    "for i in word_index_tags.items():\n",
    "    print(i)\n",
    "    tag_dir[i[0]]=np.eye(len(word_index_rev_tags))[i[1]-1]\n",
    "print(tag_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58669, 25)\n"
     ]
    }
   ],
   "source": [
    "print(tags_int_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=[]\n",
    "count=0\n",
    "for i in tags_int_padded:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "#         print(j,end=\"____\")\n",
    "        if(j==0):\n",
    "            l.append(tag_dir[\"other\"])\n",
    "        else:\n",
    "            l.append(tag_dir[word_index_rev_tags[j]])\n",
    "    l=np.array(l)\n",
    "#     print(l.shape)\n",
    "#     print(count)\n",
    "    count+=1\n",
    "    tags_vec.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58669, 25)\n",
      "(58669, 25)\n",
      "(58669, 25, 9)\n",
      "['അദ്ദേഹം', 'ജനിച്ചത്', 'തമിഴ്', 'നാട്', 'സംസ്ഥാനത്തിലെ', 'മധുരയില്', 'ആണ്', '.']\n",
      "['other', 'other', 'other', 'other', 'other', 'other', 'other', 'other']\n"
     ]
    }
   ],
   "source": [
    "print(sent_int_padded.shape)\n",
    "print(tags_int_padded.shape)\n",
    "print(np.array(tags_vec).shape)\n",
    "print(sent[0])\n",
    "\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=np.array(tags_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units=300\n",
    "from keras.layers import Embedding,InputLayer,Conv1D,MaxPooling1D,Input,Flatten,concatenate,merge,Reshape,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0=Input(shape=(max_len,))\n",
    "emb0=Embedding(len(word_index_sent)+1,max_char_len,weights=[word_char_embedding_matrix],trainable=False,input_length=max_len)(inputs0)\n",
    "emb01=TimeDistributed(Embedding(len(word_char)+1,char_embedding_size,weights=[char_embedding_matrix],trainable=False,input_length=max_char_len))(emb0)\n",
    "conv0=TimeDistributed(Conv1D(filters=20,kernel_size=5,padding=\"same\",activation=\"relu\"))(emb01)\n",
    "conv01=TimeDistributed(Conv1D(filters=11,kernel_size=5,padding=\"same\",activation=\"relu\"))(conv0)\n",
    "maxpool0=TimeDistributed(MaxPooling1D(pool_size=max_char_len))(conv01)\n",
    "# dropout0=TimeDistributed(Dropout(0.25))(maxpool0)\n",
    "newdim = tuple([x for x in maxpool0.shape.as_list() if x != 1 and x is not None])\n",
    "reshape0= Reshape(newdim) (maxpool0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_8/Reshape_1:0\", shape=(?, 25, 8, 50), dtype=float32)\n",
      "Tensor(\"time_distributed_9/Reshape_2:0\", shape=(?, 25, 8, 20), dtype=float32)\n",
      "Tensor(\"time_distributed_10/Reshape_2:0\", shape=(?, 25, 8, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(emb01)\n",
    "print(conv0)\n",
    "print(conv01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input(shape=(max_len,))\n",
    "emb1=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs1)          \n",
    "concat_0_1=concatenate([emb1,reshape0],axis=-1)\n",
    "conv1=Conv1D(filters=15,kernel_size=5,padding=\"same\",activation=\"relu\")(concat_0_1)\n",
    "# dropout1=Dropout(0.25)(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2=Input(shape=(max_len,))\n",
    "emb2=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs2)\n",
    "concat_1_2=concatenate([emb2,conv1],axis=-1)\n",
    "layers=Bidirectional(LSTM(units=num_hidden_units,input_shape=(max_len,embedding_size),return_sequences=True))(concat_1_2)\n",
    "# dropout2=Dropout(0.25)(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(len(word_index_tags),activation=\"softmax\"))(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inputs0,inputs1,inputs2],outputs=layers)\n",
    "model.compile(optimizer=\"adam\",metrics=[\"mae\",\"acc\"],loss=\"categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test=train_test_split(sent_int_padded,tags_vec,test_size=0.3,random_state=1)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "x_train=sent_int_padded\n",
    "y_train=tags_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 25, 8)        811584      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 25, 8, 50)    5072400     embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 25, 8, 20)    5020        time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 25, 8, 11)    1111        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 25, 1, 11)    0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 25, 100)      10144800    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 25, 11)       0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 25, 111)      0           embedding_7[0][0]                \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 25, 100)      10144800    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 25, 15)       8340        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 25, 115)      0           embedding_8[0][0]                \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 25, 600)      998400      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 25, 100)      60100       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 25, 100)      10100       time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 25, 9)        909         time_distributed_13[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 27,257,564\n",
      "Trainable params: 6,156,380\n",
      "Non-trainable params: 21,101,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png',show_shapes=True,show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4\n",
      "(None, 25)\n",
      "(None, 25)\n",
      "--------------------\n",
      "embedding_5\n",
      "(None, 25)\n",
      "(None, 25, 8)\n",
      "--------------------\n",
      "time_distributed_8\n",
      "(None, 25, 8)\n",
      "(None, 25, 8, 50)\n",
      "--------------------\n",
      "time_distributed_9\n",
      "(None, 25, 8, 50)\n",
      "(None, 25, 8, 20)\n",
      "--------------------\n",
      "time_distributed_10\n",
      "(None, 25, 8, 20)\n",
      "(None, 25, 8, 11)\n",
      "--------------------\n",
      "input_5\n",
      "(None, 25)\n",
      "(None, 25)\n",
      "--------------------\n",
      "time_distributed_11\n",
      "(None, 25, 8, 11)\n",
      "(None, 25, 1, 11)\n",
      "--------------------\n",
      "embedding_7\n",
      "(None, 25)\n",
      "(None, 25, 100)\n",
      "--------------------\n",
      "reshape_2\n",
      "(None, 25, 1, 11)\n",
      "(None, 25, 11)\n",
      "--------------------\n",
      "input_6\n",
      "(None, 25)\n",
      "(None, 25)\n",
      "--------------------\n",
      "concatenate_3\n",
      "[(None, 25, 100), (None, 25, 11)]\n",
      "(None, 25, 111)\n",
      "--------------------\n",
      "embedding_8\n",
      "(None, 25)\n",
      "(None, 25, 100)\n",
      "--------------------\n",
      "conv1d_6\n",
      "(None, 25, 111)\n",
      "(None, 25, 15)\n",
      "--------------------\n",
      "concatenate_4\n",
      "[(None, 25, 100), (None, 25, 15)]\n",
      "(None, 25, 115)\n",
      "--------------------\n",
      "bidirectional_2\n",
      "(None, 25, 115)\n",
      "(None, 25, 600)\n",
      "--------------------\n",
      "time_distributed_12\n",
      "(None, 25, 600)\n",
      "(None, 25, 100)\n",
      "--------------------\n",
      "time_distributed_13\n",
      "(None, 25, 100)\n",
      "(None, 25, 100)\n",
      "--------------------\n",
      "time_distributed_14\n",
      "(None, 25, 100)\n",
      "(None, 25, 9)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    print(i.name)\n",
    "    print(i.input_shape)\n",
    "    print(i.output_shape)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2063"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in y_train:\n",
    "# #     print(i)\n",
    "#     print(len(i))\n",
    "#     print(\"------------------\")\n",
    "len(char_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in x_train[:1000]:\n",
    "#     for j in i:\n",
    "#         if(j==0):\n",
    "#             break\n",
    "#         print(word_index_rev_sent[j],end=\"/\")\n",
    "#         l=[]\n",
    "#         for k in word_char_int[j]:\n",
    "#             if(k==0):\n",
    "#                 break\n",
    "#             l.append(char_index_rev[k])\n",
    "#         print(\"\".join(l),end=\" \")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46935 samples, validate on 11734 samples\n",
      "Epoch 1/25\n",
      " 1770/46935 [>.............................] - ETA: 22:55 - loss: 0.3113 - mean_absolute_error: 0.0295 - acc: 0.9230"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-895ee755e858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for i in range(epochs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n\u001b[0;32m----> 6\u001b[0;31m     EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "prev_loss=1\n",
    "loss_increase_warning=0\n",
    "# for i in range(epochs):\n",
    "his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n",
    "    EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_hindi_safe.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model_hindi_safe.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ner_malyalam_safe_final_complete_training.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### to predict load the new model along with the weights\n",
    "from keras.models import load_model\n",
    "model = load_model('ner_malyalam_safe_final_complete_training.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)==model2.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ans=model.predict([x_test,x_test,x_test])\n",
    "# c_other=0\n",
    "# i_other=0\n",
    "# c_non=0\n",
    "# i_non=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### to predict load the new model along with the weights\n",
    "# from keras.models import load_model\n",
    "# model = load_model('ner_kannada_safe_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in padded_x_test:\n",
    "    if(len(i)!=max_len):\n",
    "        print(i)\n",
    "# padded_x_test=np.array(padded_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "incorrect=0\n",
    "for i in range(len(my_ans)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(pre_y_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j,k in zip(my_ans[i],pre_y_test[i]):\n",
    "        if(j==k):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "#     print(\"-----------------------------------------------------------------\")\n",
    "print(\"accuracy=\",(correct)/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=np.zeros(shape=(len(word_index_rev_tags),len(word_index_rev_tags)),dtype=\"int32\")\n",
    "for i,j in zip(my_ans,pre_y_test):\n",
    "#     print(i)\n",
    "#     print(j)\n",
    "#     print(\"----------------\")\n",
    "    for ii,jj in zip(i,j):\n",
    "        x=word_index_tags[ii]\n",
    "        y=word_index_tags[jj]\n",
    "#         print(x,y)\n",
    "        confusion_matrix[x-1][y-1]+=1\n",
    "#         for i in confusion_matrix:\n",
    "#             print(i)\n",
    "#         print(\"-------------------\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word_index_rev_tags)):\n",
    "    print(word_index_rev_tags[i+1])\n",
    "    row_sum=0\n",
    "    col_sum=0\n",
    "    for j in range(len(word_index_rev_tags)):\n",
    "        row_sum+=confusion_matrix[i][j]\n",
    "        col_sum+=confusion_matrix[j][i]\n",
    "    p=confusion_matrix[i][i]/row_sum\n",
    "    r=confusion_matrix[i][i]/col_sum\n",
    "    f1=(2*p*r)/(p+r)\n",
    "    print(\"precision=\",p)\n",
    "    print(\"recall=\",r)\n",
    "    print(\"f1 score=\",f1)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_other=0\n",
    "i_other=0\n",
    "c_non=0\n",
    "i_non=0\n",
    "for i,j in zip(pre_y_test,my_ans):\n",
    "#     print(i,j)\n",
    "    for ii,jj in zip(i,j):\n",
    "#         print(x,y)\n",
    "        x=ii\n",
    "        y=jj\n",
    "        if(x==y):\n",
    "            if(x==\"other\"):\n",
    "                c_other+=1\n",
    "            else:\n",
    "                c_non+=1\n",
    "        elif(x!=y):\n",
    "            if(x==\"other\"):\n",
    "                i_other+=1\n",
    "            else:\n",
    "                i_non+=1\n",
    "#other accuracy\n",
    "print(\"other accuracy\")\n",
    "print(\"correct\",c_other)\n",
    "print(\"incorrect\",i_other)\n",
    "print(c_other/(c_other+i_other))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"non other accuracy\")\n",
    "print(\"correct\",c_non)\n",
    "print(\"incorrect\",i_non)\n",
    "print(c_non/(c_non+i_non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################final testing########################\n",
    "data_div=1\n",
    "pre_x_test=[]\n",
    "with codecs.open(\"v1_test2.ml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    for i in f:\n",
    "        i=i.strip()\n",
    "        if(i==\"newline\"):\n",
    "            pre_x_test.append(l1)\n",
    "#             print(len(pre_x_test))\n",
    "            l1=[]\n",
    "        else:\n",
    "            l1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl=open(\"q2.ml\",\"w\")\n",
    "for i in range(len(pre_x_test)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        fl.write(my_ans[i][j]+\"\\n\")\n",
    "    fl.write(\"newline\\n\")\n",
    "#     print(\"---------------------\")\n",
    "fl.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
