{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D\n",
    "from keras.models import Sequential,Model\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Bidirectional,TimeDistributed\n",
    "import numpy as np\n",
    "import codecs\n",
    "import regex\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_div=1\n",
    "sent=[]\n",
    "tags=[]\n",
    "with codecs.open(\"v1_train.te\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in f:\n",
    "        x=i.split()\n",
    "        if(x[0]==\"newline\"):\n",
    "            sent.append(l1)\n",
    "            tags.append(l2)\n",
    "            l1=[]\n",
    "            l2=[]\n",
    "        else:\n",
    "            l1.append(x[0])\n",
    "            l2.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63223\n",
      "200060\n",
      "{'location': 95756, 'occupation': 8437, 'name': 60499, 'datenum': 2521, 'number': 28618, 'things': 1069, 'other': 577625, 'organization': 2431, 'event': 729}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(sent))\n",
    "tag_count=0\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        if(j!=\"other\"):\n",
    "            tag_count+=1\n",
    "print(tag_count)\n",
    "tag_map={'datenum': 0,\n",
    " 'event': 0,\n",
    " 'location': 0,\n",
    " 'name': 0,\n",
    " 'number': 0,\n",
    " 'occupation': 0,\n",
    " 'organization': 0,\n",
    " 'other': 0,\n",
    " 'things': 0}\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        tag_map[j]+=1\n",
    "print(tag_map)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56900\n",
      "56900\n",
      "6323\n",
      "6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagar/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sagar/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sent,pre_x_test,tags,pre_y_test=train_test_split(sent,tags,test_size=0.1,random_state=1)\n",
    "print(len(sent))\n",
    "print(len(tags))\n",
    "print(len(pre_x_test))\n",
    "print(len(pre_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 8990\n",
      "1 : 10323\n",
      "2 : 8196\n",
      "3 : 5380\n",
      "4 : 5310\n",
      "5 : 9749\n",
      "6 : 4407\n",
      "7 : 1552\n",
      "8 : 1213\n",
      "9 : 651\n",
      "10 : 363\n",
      "11 : 253\n",
      "12 : 165\n",
      "13 : 112\n",
      "14 : 66\n",
      "15 : 37\n",
      "16 : 38\n",
      "17 : 10\n",
      "18 : 14\n",
      "19 : 18\n",
      "20 : 9\n",
      "21 : 6\n",
      "22 : 3\n",
      "23 : 4\n",
      "24 : 5\n",
      "25 : 1\n",
      "26 : 2\n",
      "27 : 3\n",
      "28 : 1\n",
      "29 : 1\n",
      "30 : 2\n",
      "31 : 4\n",
      "32 : 2\n",
      "34 : 1\n",
      "36 : 1\n",
      "39 : 1\n",
      "41 : 1\n",
      "44 : 1\n",
      "48 : 1\n",
      "62 : 1\n",
      "68 : 1\n",
      "78 : 1\n",
      "205 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_distribution(sent,tags):\n",
    "    cnt_dict={}\n",
    "    for i in tags:\n",
    "        cnt=0\n",
    "        for j in i:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in cnt_dict):\n",
    "            cnt_dict[cnt]+=1\n",
    "        else:\n",
    "            cnt_dict[cnt]=1\n",
    "    cnt_list=list(cnt_dict.keys())\n",
    "    cnt_list.sort()\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in cnt_list:\n",
    "        print(i,\":\",cnt_dict[i])\n",
    "        l1.append(i)\n",
    "        l2.append(cnt_dict[i])\n",
    "    plt.plot(l1,l2)\n",
    "    plt.xlabel(\"no. of non-other tags in the sentence\")\n",
    "    plt.ylabel(\"no. of sentences\")\n",
    "    plt.show()\n",
    "get_data_distribution(sent,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56900\n",
      "56900\n"
     ]
    }
   ],
   "source": [
    "def filter_data(sent,tags,exclude_list):\n",
    "    sent_filter=[]\n",
    "    tags_filter=[]\n",
    "    for i in range(len(tags)):\n",
    "    #     print(tags[i])\n",
    "        cnt=0\n",
    "        for j in tags[i]:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in exclude_list):\n",
    "            continue\n",
    "        if(cnt>=0):\n",
    "            sent_filter.append(sent[i])\n",
    "            tags_filter.append(tags[i])\n",
    "    return sent_filter,tags_filter\n",
    "sent_filter,tags_filter=filter_data(sent,tags,[])\n",
    "print(len(sent_filter))\n",
    "print(len(tags_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_len= 56900\n",
      "new_len= 56900\n"
     ]
    }
   ],
   "source": [
    "sent=sent_filter\n",
    "tags=tags_filter\n",
    "def divide_data_pactise(sent,tags,data_div):\n",
    "    print(\"initial_len=\",len(sent))\n",
    "    sent=sent[:len(sent)//data_div]\n",
    "    tags=tags[:len(tags)//data_div]\n",
    "    return sent,tags\n",
    "sent,tags=divide_data_pactise(sent,tags,data_div)\n",
    "print(\"new_len=\",len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ఈయన', 'తాత', 'రాయ్', 'బహాదుర్', 'సేఠ్', 'బన్సీలాల్', 'ను', 'బ్రిటీషు', 'ప్రభుత్వం', 'సర్', 'బిరుదాంకితున్ని', 'చేసి', 'గౌరవించింది', '.']\n",
      "['ముషిడిపల్లి', ',', 'విశాఖపట్నం', 'జిల్లా', ',', 'దేవరాపల్లి', 'మండలానికి', 'చెందిన', 'గ్రామము', '.']\n",
      "['సౌందర్య', 'జులై', '18', ',', '1972', '-', 'ఏప్రిల్', '17', ',', '2004', 'ప్రముఖ', 'సినీనటి', '.']\n",
      "['భావన్నపాలెం', ',', 'ఖమ్మం', 'జిల్లా', ',', 'పెనుబల్లి', 'మండలానికి', 'చెందిన', 'గ్రామము', '.']\n",
      "['అది', 'ఆ', 'దేశానికి', 'వెళితే', 'కానీ', 'తెలియదు', '.']\n",
      "['వెంకటాపురం', ',', 'ముదిగొండ', ',', 'ఖమ్మం', 'జిల్లా', ',', 'ముదిగొండ', 'మండలానికి', 'చెందిన', 'గ్రామము', '.']\n",
      "['రాజపుత్రుల', 'సంతతివారు', 'ఇప్పటికీ', 'వారి', 'హోదాలో', 'కొనసాగుతున్నారు', '.']\n",
      "['సిర్పూర్', ',', 'నిజామాబాదు', 'జిల్లా', ',', 'మద్నూరు', 'మండలానికి', 'చెందిన', 'గ్రామము', '.']\n",
      "['జంపపాలెం', ',', 'విశాఖపట్నం', 'జిల్లా', ',', 'ఎలమంచిలి', 'మండలానికి', 'చెందిన', 'గ్రామము', '.']\n",
      "['ను', 'ప్రస్తుతం', 'చిహ్నం', 'ఆధ్వర్యంలోని', 'ఇంటర్', '\\u200c', 'యాక్టివ్', '\\u200c', 'కార్ప్', 'కలిగి', 'ఉంది', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in sent[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent_len 844\n",
      "avg_sent_len 12.298664323374341\n",
      "max_sent_len_fit 24\n"
     ]
    }
   ],
   "source": [
    "max_sent_len=-1\n",
    "for i in sent:\n",
    "    if(len(i)>max_sent_len):\n",
    "        max_sent_len=len(i)\n",
    "print(\"max_sent_len\",max_sent_len)\n",
    "avg_sent_len=0\n",
    "for i in sent:\n",
    "    avg_sent_len+=len(i)\n",
    "avg_sent_len=avg_sent_len/len(sent)\n",
    "print(\"avg_sent_len\",avg_sent_len)\n",
    "max_len=int(2*(avg_sent_len))\n",
    "print(\"max_sent_len_fit\",max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex.findall(r'\\X', sent[0][0])\n",
    "def separate_into_char(sent):\n",
    "    char=[]\n",
    "    for i in sent:\n",
    "        for j in i:\n",
    "            l=regex.findall(r'\\X',j)\n",
    "            char.append(l)\n",
    "    return char\n",
    "char=separate_into_char(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ఈ', 'య', 'న']\n",
      "['తా', 'త']\n",
      "['రా', 'య్']\n",
      "['బ', 'హా', 'దు', 'ర్']\n",
      "['సే', 'ఠ్']\n",
      "['బ', 'న్', 'సీ', 'లా', 'ల్']\n",
      "['ను']\n",
      "['బ్', 'రి', 'టీ', 'షు']\n",
      "['ప్', 'ర', 'భు', 'త్', 'వం']\n",
      "['స', 'ర్']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in char[:10]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_size=50\n",
    "word_min_count=1\n",
    "c2v=Word2Vec(char,size=char_embedding_size,min_count=word_min_count)\n",
    "# print(c2v.wv[\"ल\"])\n",
    "# c2v.wv.most_similar(positive=\"ा\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c2v.wv.most_similar(positive=\"क\")\n",
    "len(c2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "1172\n"
     ]
    }
   ],
   "source": [
    "tokenizer_char=Tokenizer()\n",
    "tokenizer_char.fit_on_texts(char)\n",
    "char_index=tokenizer_char.word_index\n",
    "print(len(char_index))\n",
    "num_char=(len(char_index)*3)//4\n",
    "print(num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "<UNK_CHAR>\n"
     ]
    }
   ],
   "source": [
    "def add_unk_char(char_index,num_char):\n",
    "    ref={}\n",
    "    for i,j in char_index.items():\n",
    "        if(j<=num_char):\n",
    "            ref[i]=j\n",
    "    ref[\"<UNK_CHAR>\"]=num_char+1\n",
    "    char_index=ref\n",
    "    char_index_rev={}\n",
    "    for (i,j) in char_index.items():\n",
    "        char_index_rev[j]=i\n",
    "    print(char_index[\"<UNK_CHAR>\"])\n",
    "    print(char_index_rev[char_index[\"<UNK_CHAR>\"]])\n",
    "    return char_index,char_index_rev\n",
    "char_index,char_index_rev=add_unk_char(char_index,num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of chars: 1173\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of chars:\",len(char_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "3.265350946135577\n",
      "max_char_len_fit 6\n"
     ]
    }
   ],
   "source": [
    "max_char_len=-1\n",
    "for i in char:\n",
    "    if(len(i)>max_char_len):\n",
    "        max_char_len=len(i)\n",
    "print(max_char_len)\n",
    "avg_char_len=0\n",
    "for i in char:\n",
    "    avg_char_len+=len(i)\n",
    "avg_char_len=avg_char_len/len(char)\n",
    "print(avg_char_len)\n",
    "max_char_len=int(2*avg_char_len)\n",
    "print(\"max_char_len_fit\",max_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words: 101048\n",
      "No. of tags: 9\n",
      "75786\n"
     ]
    }
   ],
   "source": [
    "tokenizer_sent=Tokenizer()\n",
    "tokenizer_tags=Tokenizer()\n",
    "tokenizer_sent.fit_on_texts(sent)\n",
    "tokenizer_tags.fit_on_texts(tags)\n",
    "word_index_sent=tokenizer_sent.word_index\n",
    "word_index_tags=tokenizer_tags.word_index\n",
    "print(\"No. of words:\",len(word_index_sent))\n",
    "print(\"No. of tags:\",len(word_index_tags))\n",
    "num_words=(len(word_index_sent)*3)//4\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref={}\n",
    "for i,j in word_index_sent.items():\n",
    "    if(j<=num_words):\n",
    "        ref[i]=j\n",
    "ref[\"<UNK_WORD>\"]=num_words+1\n",
    "word_index_sent=ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_rev_sent={}\n",
    "word_index_rev_tags={}\n",
    "for i,j in word_index_sent.items():\n",
    "    word_index_rev_sent[j]=i\n",
    "for i,j in word_index_tags.items():\n",
    "    word_index_rev_tags[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char={}\n",
    "for i,j in word_index_sent.items():\n",
    "#     print(i,j)\n",
    "    l=[]\n",
    "    if(i==\"<UNK_WORD>\"):\n",
    "        l=[char_index[\"<UNK_CHAR>\"]]*max_char_len\n",
    "        word_char[i]=l\n",
    "#         print(l)\n",
    "        continue\n",
    "    for k in regex.findall(r'\\X',i):\n",
    "        if(k in char_index):\n",
    "#             print(k,end=\"-\")\n",
    "            h=char_index[k]\n",
    "        else:\n",
    "#             print(k)\n",
    "            h=char_index[\"<UNK_CHAR>\"]\n",
    "#         else:\n",
    "#             print(i)\n",
    "#             print(k,end=\"-\")\n",
    "#             h=char_index[\"<UNK_CHAR>\"]\n",
    "#             print(\"********\")\n",
    "#             print(\"------------------------------\")\n",
    "#             #         print(h)\n",
    "        l.append(h)\n",
    "    word_char[i]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char.items():\n",
    "#     print(i)\n",
    "# print(word_char[\"<UNK_WORD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in word_char.items():\n",
    "    word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75787\n",
      "('తారీఖుల', array([ 82,  85, 380,   8,   0,   0], dtype=int32))\n",
      "('గొయ్యిగుంట', array([251, 174,  84, 223,  56,   0], dtype=int32))\n",
      "('వాటాదారుల', array([ 48, 130,  86,  19,   8,   0], dtype=int32))\n",
      "('చర్మానికి', array([72,  6, 52,  4, 27,  0], dtype=int32))\n",
      "('బేరు', array([344,  19,   0,   0,   0,   0], dtype=int32))\n",
      "('కేంద్రం', array([237,  45,  38,   0,   0,   0], dtype=int32))\n",
      "('తాంస', array([378,  50,   0,   0,   0,   0], dtype=int32))\n",
      "('పళ్ళను', array([ 21, 141, 181,  60,   0,   0], dtype=int32))\n",
      "('చప్పిడివాండ్లపల్లె', array([408,  51,   8,  21,  10, 168], dtype=int32))\n",
      "('ఛెప్పి', array([603,  25,  90,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_char={}\n",
    "# for i,j in word_index_sent.items():\n",
    "#     l=[]\n",
    "#     for k in regex.findall(r'\\X',i):\n",
    "#         if(k in char_index):\n",
    "#             l.append(char_index[k])\n",
    "#         else:\n",
    "#             l.append(char_index[\"<UNK_CHAR>\"])\n",
    "#     word_char[i]=l\n",
    "# for i,j in word_char.items():\n",
    "#     word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75787\n",
      "('తారీఖుల', array([ 82,  85, 380,   8,   0,   0], dtype=int32))\n",
      "('గొయ్యిగుంట', array([251, 174,  84, 223,  56,   0], dtype=int32))\n",
      "('వాటాదారుల', array([ 48, 130,  86,  19,   8,   0], dtype=int32))\n",
      "('చర్మానికి', array([72,  6, 52,  4, 27,  0], dtype=int32))\n",
      "('బేరు', array([344,  19,   0,   0,   0,   0], dtype=int32))\n",
      "('కేంద్రం', array([237,  45,  38,   0,   0,   0], dtype=int32))\n",
      "('తాంస', array([378,  50,   0,   0,   0,   0], dtype=int32))\n",
      "('పళ్ళను', array([ 21, 141, 181,  60,   0,   0], dtype=int32))\n",
      "('చప్పిడివాండ్లపల్లె', array([408,  51,   8,  21,  10, 168], dtype=int32))\n",
      "('ఛెప్పి', array([603,  25,  90,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_int={}\n",
    "for i,j in word_char.items():\n",
    "    word_char_int[word_index_sent[i]]=j\n",
    "# for i in word_char_int.items():\n",
    "#     print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_embedding_matrix=np.zeros((len(word_char) + 1, max_char_len))\n",
    "for i,j in word_char_int.items():\n",
    "    word_char_embedding_matrix[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char_embedding_matrix:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75788, 50)\n"
     ]
    }
   ],
   "source": [
    "char_embedding_matrix = np.zeros((len(word_char) + 1, char_embedding_size))\n",
    "for i,j in char_index_rev.items():\n",
    "    if(j in c2v.wv.vocab):\n",
    "        char_embedding_matrix[i]=c2v.wv[j]\n",
    "print(char_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in char_embedding_matrix:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_int=[]\n",
    "for i in word_char_int.items():\n",
    "    char_int.append(i[1])\n",
    "# print(char_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datenum': 6,\n",
       " 'event': 9,\n",
       " 'location': 2,\n",
       " 'name': 3,\n",
       " 'number': 4,\n",
       " 'occupation': 5,\n",
       " 'organization': 7,\n",
       " 'other': 1,\n",
       " 'things': 8}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK_WORD>\n"
     ]
    }
   ],
   "source": [
    "# word_char[\"<UNK_WORD>\"]#array([2389, 2389, 2389, 2389, 2389], dtype=int32)\n",
    "# word_index_sent[\"<UNK_WORD>\"]#2389\n",
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j==\"<UNK_WORD>\"):\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int=[]\n",
    "for i in sent:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    sent_int.append(l)\n",
    "tags_int=[]\n",
    "for i in tags:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        l.append(word_index_tags[j])\n",
    "    tags_int.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int_padded=pad_sequences(sent_int,maxlen=max_len,padding='post')\n",
    "tags_int_padded=pad_sequences(tags_int,maxlen=max_len,padding=\"post\")\n",
    "# for i in tags_int_padded:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=100\n",
    "workers=5\n",
    "window_size=5\n",
    "word_min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sent:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75788, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v=Word2Vec(sent,size=embedding_size,workers=workers,window=window_size,min_count=word_min_count)\n",
    "embedding_matrix = np.zeros((len(word_index_sent) + 1, embedding_size))\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.01467825e-01  7.06774950e-01 -1.37885976e+00 ... -2.24293494e+00\n",
      "  -1.17928229e-01  1.00047207e+00]\n",
      " [ 3.65822345e-01 -4.12600562e-02  2.58563757e-01 ... -2.29337955e+00\n",
      "   1.32680571e+00  7.06884325e-01]\n",
      " ...\n",
      " [ 2.38899258e-03  8.25362187e-03 -4.01784433e-03 ... -4.04592091e-03\n",
      "   4.04206058e-03 -3.61227058e-03]\n",
      " [-3.19019938e-03  1.57769921e-03 -4.84490301e-03 ... -8.31121765e-03\n",
      "   1.14596868e-03  7.11006066e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j in w2v.wv.vocab):\n",
    "        embedding_matrix[i]=w2v.wv[j]\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number', 4)\n",
      "('organization', 7)\n",
      "('location', 2)\n",
      "('datenum', 6)\n",
      "('other', 1)\n",
      "('occupation', 5)\n",
      "('event', 9)\n",
      "('name', 3)\n",
      "('things', 8)\n",
      "{'number': array([0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'event': array([0., 0., 0., 0., 0., 0., 0., 0., 1.]), 'name': array([0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'location': array([0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'datenum': array([0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'other': array([1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'occupation': array([0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'organization': array([0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'things': array([0., 0., 0., 0., 0., 0., 0., 1., 0.])}\n"
     ]
    }
   ],
   "source": [
    "tag_dir={}\n",
    "for i in word_index_tags.items():\n",
    "    print(i)\n",
    "    tag_dir[i[0]]=np.eye(len(word_index_rev_tags))[i[1]-1]\n",
    "print(tag_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56900, 24)\n"
     ]
    }
   ],
   "source": [
    "print(tags_int_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=[]\n",
    "count=0\n",
    "for i in tags_int_padded:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "#         print(j,end=\"____\")\n",
    "        if(j==0):\n",
    "            l.append(tag_dir[\"other\"])\n",
    "        else:\n",
    "            l.append(tag_dir[word_index_rev_tags[j]])\n",
    "    l=np.array(l)\n",
    "#     print(l.shape)\n",
    "#     print(count)\n",
    "    count+=1\n",
    "    tags_vec.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56900, 24)\n",
      "(56900, 24)\n",
      "(56900, 24, 9)\n",
      "['ఈయన', 'తాత', 'రాయ్', 'బహాదుర్', 'సేఠ్', 'బన్సీలాల్', 'ను', 'బ్రిటీషు', 'ప్రభుత్వం', 'సర్', 'బిరుదాంకితున్ని', 'చేసి', 'గౌరవించింది', '.']\n",
      "['other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'name', 'other', 'other', 'other', 'other']\n"
     ]
    }
   ],
   "source": [
    "print(sent_int_padded.shape)\n",
    "print(tags_int_padded.shape)\n",
    "print(np.array(tags_vec).shape)\n",
    "print(sent[0])\n",
    "\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=np.array(tags_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units=300\n",
    "from keras.layers import Embedding,InputLayer,Conv1D,MaxPooling1D,Input,Flatten,concatenate,merge,Reshape,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0=Input(shape=(max_len,))\n",
    "emb0=Embedding(len(word_index_sent)+1,max_char_len,weights=[word_char_embedding_matrix],trainable=False,input_length=max_len)(inputs0)\n",
    "emb01=TimeDistributed(Embedding(len(word_char)+1,char_embedding_size,weights=[char_embedding_matrix],trainable=False,input_length=max_char_len))(emb0)\n",
    "conv0=TimeDistributed(Conv1D(filters=20,kernel_size=5,padding=\"same\",activation=\"relu\"))(emb01)\n",
    "conv01=TimeDistributed(Conv1D(filters=11,kernel_size=5,padding=\"same\",activation=\"relu\"))(conv0)\n",
    "maxpool0=TimeDistributed(MaxPooling1D(pool_size=max_char_len))(conv01)\n",
    "# dropout0=TimeDistributed(Dropout(0.25))(maxpool0)\n",
    "newdim = tuple([x for x in maxpool0.shape.as_list() if x != 1 and x is not None])\n",
    "reshape0= Reshape(newdim) (maxpool0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_1/Reshape_1:0\", shape=(?, 24, 6, 50), dtype=float32)\n",
      "Tensor(\"time_distributed_2/Reshape_2:0\", shape=(?, 24, 6, 20), dtype=float32)\n",
      "Tensor(\"time_distributed_3/Reshape_2:0\", shape=(?, 24, 6, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(emb01)\n",
    "print(conv0)\n",
    "print(conv01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input(shape=(max_len,))\n",
    "emb1=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs1)          \n",
    "concat_0_1=concatenate([emb1,reshape0],axis=-1)\n",
    "conv1=Conv1D(filters=15,kernel_size=5,padding=\"same\",activation=\"relu\")(concat_0_1)\n",
    "# dropout1=Dropout(0.25)(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2=Input(shape=(max_len,))\n",
    "emb2=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs2)\n",
    "concat_1_2=concatenate([emb2,conv1],axis=-1)\n",
    "layers=Bidirectional(LSTM(units=num_hidden_units,input_shape=(max_len,embedding_size),return_sequences=True))(concat_1_2)\n",
    "# dropout2=Dropout(0.25)(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(len(word_index_tags),activation=\"softmax\"))(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inputs0,inputs1,inputs2],outputs=layers)\n",
    "model.compile(optimizer=\"adam\",metrics=[\"mae\",\"acc\"],loss=\"categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test=train_test_split(sent_int_padded,tags_vec,test_size=0.3,random_state=1)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "x_train=sent_int_padded\n",
    "y_train=tags_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 24, 6)        454728      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 24, 6, 50)    3789400     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 24, 6, 20)    5020        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 24, 6, 11)    1111        time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 24, 1, 11)    0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 24, 100)      7578800     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 24, 11)       0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24, 111)      0           embedding_3[0][0]                \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 24, 100)      7578800     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 15)       8340        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 115)      0           embedding_4[0][0]                \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 24, 600)      998400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 24, 100)      60100       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 24, 100)      10100       time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 24, 9)        909         time_distributed_6[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 20,485,708\n",
      "Trainable params: 4,873,380\n",
      "Non-trainable params: 15,612,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png',show_shapes=True,show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "(None, 24)\n",
      "(None, 24)\n",
      "--------------------\n",
      "embedding_1\n",
      "(None, 24)\n",
      "(None, 24, 6)\n",
      "--------------------\n",
      "time_distributed_1\n",
      "(None, 24, 6)\n",
      "(None, 24, 6, 50)\n",
      "--------------------\n",
      "time_distributed_2\n",
      "(None, 24, 6, 50)\n",
      "(None, 24, 6, 20)\n",
      "--------------------\n",
      "time_distributed_3\n",
      "(None, 24, 6, 20)\n",
      "(None, 24, 6, 11)\n",
      "--------------------\n",
      "input_2\n",
      "(None, 24)\n",
      "(None, 24)\n",
      "--------------------\n",
      "time_distributed_4\n",
      "(None, 24, 6, 11)\n",
      "(None, 24, 1, 11)\n",
      "--------------------\n",
      "embedding_3\n",
      "(None, 24)\n",
      "(None, 24, 100)\n",
      "--------------------\n",
      "reshape_1\n",
      "(None, 24, 1, 11)\n",
      "(None, 24, 11)\n",
      "--------------------\n",
      "input_3\n",
      "(None, 24)\n",
      "(None, 24)\n",
      "--------------------\n",
      "concatenate_1\n",
      "[(None, 24, 100), (None, 24, 11)]\n",
      "(None, 24, 111)\n",
      "--------------------\n",
      "embedding_4\n",
      "(None, 24)\n",
      "(None, 24, 100)\n",
      "--------------------\n",
      "conv1d_3\n",
      "(None, 24, 111)\n",
      "(None, 24, 15)\n",
      "--------------------\n",
      "concatenate_2\n",
      "[(None, 24, 100), (None, 24, 15)]\n",
      "(None, 24, 115)\n",
      "--------------------\n",
      "bidirectional_1\n",
      "(None, 24, 115)\n",
      "(None, 24, 600)\n",
      "--------------------\n",
      "time_distributed_5\n",
      "(None, 24, 600)\n",
      "(None, 24, 100)\n",
      "--------------------\n",
      "time_distributed_6\n",
      "(None, 24, 100)\n",
      "(None, 24, 100)\n",
      "--------------------\n",
      "time_distributed_7\n",
      "(None, 24, 100)\n",
      "(None, 24, 9)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    print(i.name)\n",
    "    print(i.input_shape)\n",
    "    print(i.output_shape)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in y_train:\n",
    "# #     print(i)\n",
    "#     print(len(i))\n",
    "#     print(\"------------------\")\n",
    "len(char_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in x_train[:1000]:\n",
    "#     for j in i:\n",
    "#         if(j==0):\n",
    "#             break\n",
    "#         print(word_index_rev_sent[j],end=\"/\")\n",
    "#         l=[]\n",
    "#         for k in word_char_int[j]:\n",
    "#             if(k==0):\n",
    "#                 break\n",
    "#             l.append(char_index_rev[k])\n",
    "#         print(\"\".join(l),end=\" \")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45520 samples, validate on 11380 samples\n",
      "Epoch 1/25\n",
      " 2540/45520 [>.............................] - ETA: 17:56 - loss: 0.2582 - mean_absolute_error: 0.0262 - acc: 0.9271"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-895ee755e858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for i in range(epochs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n\u001b[0;32m----> 6\u001b[0;31m     EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "prev_loss=1\n",
    "loss_increase_warning=0\n",
    "# for i in range(epochs):\n",
    "his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n",
    "    EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_hindi_safe.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model_hindi_safe.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ner_telugu_safe_final_complete_training.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### to predict load the new model along with the weights\n",
    "from keras.models import load_model\n",
    "model = load_model('ner_telugu_safe_final_complete_training.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)==model2.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ans=model.predict([x_test,x_test,x_test])\n",
    "# c_other=0\n",
    "# i_other=0\n",
    "# c_non=0\n",
    "# i_non=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### to predict load the new model along with the weights\n",
    "# from keras.models import load_model\n",
    "# model = load_model('ner_kannada_safe_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in padded_x_test:\n",
    "    if(len(i)!=max_len):\n",
    "        print(i)\n",
    "# padded_x_test=np.array(padded_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "incorrect=0\n",
    "for i in range(len(my_ans)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(pre_y_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j,k in zip(my_ans[i],pre_y_test[i]):\n",
    "        if(j==k):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "#     print(\"-----------------------------------------------------------------\")\n",
    "print(\"accuracy=\",(correct)/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=np.zeros(shape=(len(word_index_rev_tags),len(word_index_rev_tags)),dtype=\"int32\")\n",
    "for i,j in zip(my_ans,pre_y_test):\n",
    "#     print(i)\n",
    "#     print(j)\n",
    "#     print(\"----------------\")\n",
    "    for ii,jj in zip(i,j):\n",
    "        x=word_index_tags[ii]\n",
    "        y=word_index_tags[jj]\n",
    "#         print(x,y)\n",
    "        confusion_matrix[x-1][y-1]+=1\n",
    "#         for i in confusion_matrix:\n",
    "#             print(i)\n",
    "#         print(\"-------------------\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word_index_rev_tags)):\n",
    "    print(word_index_rev_tags[i+1])\n",
    "    row_sum=0\n",
    "    col_sum=0\n",
    "    for j in range(len(word_index_rev_tags)):\n",
    "        row_sum+=confusion_matrix[i][j]\n",
    "        col_sum+=confusion_matrix[j][i]\n",
    "    p=confusion_matrix[i][i]/row_sum\n",
    "    r=confusion_matrix[i][i]/col_sum\n",
    "    f1=(2*p*r)/(p+r)\n",
    "    print(\"precision=\",p)\n",
    "    print(\"recall=\",r)\n",
    "    print(\"f1 score=\",f1)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_other=0\n",
    "i_other=0\n",
    "c_non=0\n",
    "i_non=0\n",
    "for i,j in zip(pre_y_test,my_ans):\n",
    "#     print(i,j)\n",
    "    for ii,jj in zip(i,j):\n",
    "#         print(x,y)\n",
    "        x=ii\n",
    "        y=jj\n",
    "        if(x==y):\n",
    "            if(x==\"other\"):\n",
    "                c_other+=1\n",
    "            else:\n",
    "                c_non+=1\n",
    "        elif(x!=y):\n",
    "            if(x==\"other\"):\n",
    "                i_other+=1\n",
    "            else:\n",
    "                i_non+=1\n",
    "#other accuracy\n",
    "print(\"other accuracy\")\n",
    "print(\"correct\",c_other)\n",
    "print(\"incorrect\",i_other)\n",
    "print(c_other/(c_other+i_other))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"non other accuracy\")\n",
    "print(\"correct\",c_non)\n",
    "print(\"incorrect\",i_non)\n",
    "print(c_non/(c_non+i_non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################final testing########################\n",
    "data_div=1\n",
    "pre_x_test=[]\n",
    "with codecs.open(\"v1_test1.te\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    for i in f:\n",
    "        i=i.strip()\n",
    "        if(i==\"newline\"):\n",
    "            pre_x_test.append(l1)\n",
    "#             print(len(pre_x_test))\n",
    "            l1=[]\n",
    "        else:\n",
    "            l1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl=open(\"q1.te\",\"w\")\n",
    "for i in range(len(pre_x_test)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        fl.write(my_ans[i][j]+\"\\n\")\n",
    "    fl.write(\"newline\\n\")\n",
    "#     print(\"---------------------\")\n",
    "fl.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
