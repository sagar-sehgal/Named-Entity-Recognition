{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D\n",
    "from keras.models import Sequential,Model\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Bidirectional,TimeDistributed\n",
    "import numpy as np\n",
    "import codecs\n",
    "import regex\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_div=1\n",
    "sent=[]\n",
    "tags=[]\n",
    "with codecs.open(\"v1_train.kn\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in f:\n",
    "        x=i.split()\n",
    "        if(x[0]==\"newline\"):\n",
    "            sent.append(l1)\n",
    "            tags.append(l2)\n",
    "            l1=[]\n",
    "            l2=[]\n",
    "        else:\n",
    "            l1.append(x[0])\n",
    "            l2.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20536\n",
      "35169\n",
      "{'things': 242, 'event': 523, 'location': 10473, 'name': 15110, 'datenum': 1046, 'number': 3948, 'other': 262651, 'organization': 746, 'occupation': 3081}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(sent))\n",
    "tag_count=0\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        if(j!=\"other\"):\n",
    "            tag_count+=1\n",
    "print(tag_count)\n",
    "tag_map={'datenum': 0,\n",
    " 'event': 0,\n",
    " 'location': 0,\n",
    " 'name': 0,\n",
    " 'number': 0,\n",
    " 'occupation': 0,\n",
    " 'organization': 0,\n",
    " 'other': 0,\n",
    " 'things': 0}\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        tag_map[j]+=1\n",
    "print(tag_map)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18482\n",
      "18482\n",
      "2054\n",
      "2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagar/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sagar/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sent,pre_x_test,tags,pre_y_test=train_test_split(sent,tags,test_size=0.1,random_state=1)\n",
    "print(len(sent))\n",
    "print(len(tags))\n",
    "print(len(pre_x_test))\n",
    "print(len(pre_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 6954\n",
      "1 : 4245\n",
      "2 : 2737\n",
      "3 : 1663\n",
      "4 : 1194\n",
      "5 : 634\n",
      "6 : 363\n",
      "7 : 222\n",
      "8 : 151\n",
      "9 : 86\n",
      "10 : 75\n",
      "11 : 37\n",
      "12 : 38\n",
      "13 : 19\n",
      "14 : 13\n",
      "15 : 11\n",
      "16 : 6\n",
      "17 : 7\n",
      "18 : 4\n",
      "19 : 4\n",
      "20 : 3\n",
      "21 : 4\n",
      "22 : 5\n",
      "23 : 1\n",
      "29 : 1\n",
      "30 : 2\n",
      "32 : 1\n",
      "37 : 1\n",
      "68 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_distribution(sent,tags):\n",
    "    cnt_dict={}\n",
    "    for i in tags:\n",
    "        cnt=0\n",
    "        for j in i:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in cnt_dict):\n",
    "            cnt_dict[cnt]+=1\n",
    "        else:\n",
    "            cnt_dict[cnt]=1\n",
    "    cnt_list=list(cnt_dict.keys())\n",
    "    cnt_list.sort()\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in cnt_list:\n",
    "        print(i,\":\",cnt_dict[i])\n",
    "        l1.append(i)\n",
    "        l2.append(cnt_dict[i])\n",
    "    plt.plot(l1,l2)\n",
    "    plt.xlabel(\"no. of non-other tags in the sentence\")\n",
    "    plt.ylabel(\"no. of sentences\")\n",
    "    plt.show()\n",
    "get_data_distribution(sent,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18482\n",
      "18482\n"
     ]
    }
   ],
   "source": [
    "def filter_data(sent,tags,exclude_list):\n",
    "    sent_filter=[]\n",
    "    tags_filter=[]\n",
    "    for i in range(len(tags)):\n",
    "    #     print(tags[i])\n",
    "        cnt=0\n",
    "        for j in tags[i]:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in exclude_list):\n",
    "            continue\n",
    "        if(cnt>=0):\n",
    "            sent_filter.append(sent[i])\n",
    "            tags_filter.append(tags[i])\n",
    "    return sent_filter,tags_filter\n",
    "sent_filter,tags_filter=filter_data(sent,tags,[])\n",
    "print(len(sent_filter))\n",
    "print(len(tags_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_len= 18482\n",
      "new_len= 18482\n"
     ]
    }
   ],
   "source": [
    "sent=sent_filter\n",
    "tags=tags_filter\n",
    "def divide_data_pactise(sent,tags,data_div):\n",
    "    print(\"initial_len=\",len(sent))\n",
    "    sent=sent[:len(sent)//data_div]\n",
    "    tags=tags[:len(tags)//data_div]\n",
    "    return sent,tags\n",
    "sent,tags=divide_data_pactise(sent,tags,data_div)\n",
    "print(\"new_len=\",len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ಆದರೆ', 'ಮೇ', '೧೯೯೮ರಲ್ಲಿ', 'ಇತಿಯೋಪಿಯದೊಂದಿಗೆ', 'ಪುನಃ', 'ಯುದ್ಧ', 'ಪ್ರಾರಂಭವಾದುದರಿಂದ', 'ಈ', 'ಸಂವಿಧಾನ', 'ಕಾರ್ಯಕ್ಕೆ', 'ಬಂದಿಲ್ಲ', '.']\n",
      "['ಬ್ಯಾರಿಮೋರ್', 'ಅಭಿನಯದ', 'ಚಾರ್ಲೀಸ್\\u200c', 'ಏಂಜೆಲ್ಸ್', '\\u200c', ',', '50', 'ಫಸ್ಟ್\\u200c', 'ಡೇಟ್ಸ್', '\\u200c', ',', 'ಮತ್ತು', 'ಮ್ಯೂಸಿಕ್\\u200c', 'ಅಂಡ್', 'ಲಿರಿಕ್ಸ್\\u200c', 'ಎಂಬ', 'ಚಲನಚಿತ್ರಗಳ', 'ಜೊತೆಗೇ', ',', 'ಡೋನಿ', 'ಡಾರ್ಕೊ', 'ನಂಥ', 'ಧಾರ್ಮಿಕ', 'ನಂಬುಗೆಯ', 'ಕುರಿತಾದ', 'ಚಿತ್ರವನ್ನೂ', 'ಸಹ', 'ಫ್ಲವರ್', 'ಫಿಲ್ಮ್ಸ್\\u200c', 'ಸಂಸ್ಥೆ', 'ನಿರ್ಮಿಸುತ್ತಾ', 'ಬಂದಿದೆ', '.']\n",
      "['ಹದಿನಾರನೇ', 'ವಯಸ್ಸಿನಲ್ಲಿ', 'ಅವರು', 'ಭಾನುಶಿಂಘೊ', 'ಸೂರ್ಯ', 'ಸಿಂಹ', 'ಎಂಬ', 'ಗುಪ್ತನಾಮದಡಿ', 'ಮೊದಲ', 'ಮಹತ್ವದ', 'ಕವನವನ್ನು', 'ಪ್ರಕಟಿಸಿದರು', 'ಮತ್ತು', 'ಅವರು', 'ಮೊದಲು', 'ಸಣ್ಣ', 'ಕಥೆಗಳು', 'ಮತ್ತು', 'ನಾಟಕಗಳನ್ನು', '೧೮೭೭ರಲ್ಲಿ', 'ಬರೆದರು', '.']\n",
      "['ಇಸವಿ', '2003ರಲ್ಲಿ', 'ಬಿಡುಗಡೆಯಾದ', 'ಹೇಯ್ಲ್\\u200c', 'ಟು', 'ದಿ', 'ಥೀಫ್', '\\u200c', 'ಆಲ್ಬಮ್\\u200cನಲ್ಲಿ', 'ಯುದ್ಧದಿಂದ', 'ಸ್ಫೂರ್ತಿ', 'ಪಡೆದ', 'ಗಿಟಾರ್\\u200c', '-', 'ಚಾಲಿತ', 'ರಾಕ್\\u200c', ',', 'ವಿದ್ಯುನ್ಮಾನ', 'ಮತ್ತು', 'ಗೀತೆಗಳಿದ್ದವು', '.']\n",
      "['ಮುಳ್ಳಯ್ಯನಗಿರಿ', 'ಭಾರತದ', 'ಕರ್ನಾಟಕ', 'ರಾಜ್ಯದ', 'ಚಿಕ್ಕಮಗಳೂರು', 'ಜಿಲ್ಲೆಯಲ್ಲಿ', 'ಪಶ್ಚಿಮ', 'ಘಟ್ಟಗಳ', 'ಬಾಬಾ', 'ಬುಡನ್\\u200cಗಿರಿ', 'ಬೆಟ್ಟಸಾಲಿನಲ್ಲಿರುವ', 'ಒಂದು', 'ಶಿಖರ', '.']\n",
      "['ಅವರು', 'ನಟಿಸಿದ', 'ಚಿತ್ರಗಳ', 'ಸಂಖ್ಯೆ', '೩೫೦ಕ್ಕೂ', 'ಹೆಚ್ಚಿನದು', '.']\n",
      "['ಈ', 'ಎರಡು', 'ಚಿತ್ರಗಳಲ್ಲಿಯು', 'ಅವರಿಗೆ', 'ರಾಷ್ಟ್ರೀಯ', 'ಚಲನಚಿತ್ರ', 'ಪ್ರಶಸ್ತಿ', 'ದೊರೆತಿದೆ', '.']\n",
      "['೧', 'ಹಾಗೂ', '-', '೧೯೯೯', 'ನಂತಹ', 'ವ್ಯಾವಹಾರಿಕವಾಗಿ', 'ಯಶಸ್ವಿಯಾದ', 'ಚಿತ್ರಗಳೂ', 'ಕಡಿಮೆ', ',', 'ಹಾಗೂ', 'ಈ', 'ಚಿತ್ರಗಳಲ್ಲಿ', 'ಅವರ', 'ಪಾತ್ರಗಳೂ', 'ಬಹಳ', 'ಚಿಕ್ಕವು', '.']\n",
      "['ಕುಂ', 'ವೀಯವರು', 'ಬಾಲ್ಯದಿಂದ', 'ಹಿಡಿದು', ',', 'ಅಮೆರಿಕಾದ', 'ಅಕ್ಕ', 'ಸಮ್ಮೇಳನದವರೆಗೆ', 'ಬೆಳೆದ', 'ಕುಂವೀಯನ್ನು', 'ಈ', 'ಕೃತಿಯಲ್ಲಿ', 'ಕಾಣಬುಹುದಾಗಿದೆ', 'ಬಳ್ಳಾರಿ', 'ಜಿಲ್ಲೆಯ', 'ಗ್ರಾಮೀಣ', 'ಭಾಷೆಯ', 'ಸೊಗಡನ್ನು', 'ಆತ್ಮಕಥನದ', 'ಸನ್ನಿವೇಶಗಳಲ್ಲಿ', 'ಹಿಡಿದಿಡುತ್ತಲೇ', ',', 'ಹಿಂದುಳಿದ', 'ಜನಾಂಗದ', 'ಬದುಕಿನ', 'ಬವಣೆಗಳನ್ನು', 'ಕಣ್ಣಿಗೆ', 'ಕಟ್ಟುವಂತೆ', 'ಲೇಖಕರು', 'ಚಿತ್ರಿಸುತ್ತಾರೆ', '.']\n",
      "['ವಿ', 'ರವಿಚಂದ್ರನ್ರವರು', 'ಈ', 'ಚಿತ್ರವನ್ನು', 'ನಿರ್ಮಾನಿಸಿದ್ದಾರೆ', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in sent[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent_len 184\n",
      "avg_sent_len 14.478844280921978\n",
      "max_sent_len_fit 28\n"
     ]
    }
   ],
   "source": [
    "max_sent_len=-1\n",
    "for i in sent:\n",
    "    if(len(i)>max_sent_len):\n",
    "        max_sent_len=len(i)\n",
    "print(\"max_sent_len\",max_sent_len)\n",
    "avg_sent_len=0\n",
    "for i in sent:\n",
    "    avg_sent_len+=len(i)\n",
    "avg_sent_len=avg_sent_len/len(sent)\n",
    "print(\"avg_sent_len\",avg_sent_len)\n",
    "max_len=int(2*(avg_sent_len))\n",
    "# max_len=28\n",
    "print(\"max_sent_len_fit\",max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex.findall(r'\\X', sent[0][0])\n",
    "def separate_into_char(sent):\n",
    "    char=[]\n",
    "    for i in sent:\n",
    "        for j in i:\n",
    "            l=regex.findall(r'\\X',j)\n",
    "            char.append(l)\n",
    "    return char\n",
    "char=separate_into_char(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ಆ', 'ದ', 'ರೆ']\n",
      "['ಮೇ']\n",
      "['೧', '೯', '೯', '೮', 'ರ', 'ಲ್', 'ಲಿ']\n",
      "['ಇ', 'ತಿ', 'ಯೋ', 'ಪಿ', 'ಯ', 'ದೊಂ', 'ದಿ', 'ಗೆ']\n",
      "['ಪು', 'ನಃ']\n",
      "['ಯು', 'ದ್', 'ಧ']\n",
      "['ಪ್', 'ರಾ', 'ರಂ', 'ಭ', 'ವಾ', 'ದು', 'ದ', 'ರಿಂ', 'ದ']\n",
      "['ಈ']\n",
      "['ಸಂ', 'ವಿ', 'ಧಾ', 'ನ']\n",
      "['ಕಾ', 'ರ್', 'ಯ', 'ಕ್', 'ಕೆ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in char[:10]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_size=50\n",
    "word_min_count=1\n",
    "c2v=Word2Vec(char,size=char_embedding_size,min_count=word_min_count)\n",
    "# print(c2v.wv[\"ल\"])\n",
    "# c2v.wv.most_similar(positive=\"ा\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c2v.wv.most_similar(positive=\"क\")\n",
    "len(c2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899\n",
      "1424\n"
     ]
    }
   ],
   "source": [
    "tokenizer_char=Tokenizer()\n",
    "tokenizer_char.fit_on_texts(char)\n",
    "char_index=tokenizer_char.word_index\n",
    "print(len(char_index))\n",
    "num_char=(len(char_index)*3)//4\n",
    "print(num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425\n",
      "<UNK_CHAR>\n"
     ]
    }
   ],
   "source": [
    "def add_unk_char(char_index,num_char):\n",
    "    ref={}\n",
    "    for i,j in char_index.items():\n",
    "        if(j<=num_char):\n",
    "            ref[i]=j\n",
    "    ref[\"<UNK_CHAR>\"]=num_char+1\n",
    "    char_index=ref\n",
    "    char_index_rev={}\n",
    "    for (i,j) in char_index.items():\n",
    "        char_index_rev[j]=i\n",
    "    print(char_index[\"<UNK_CHAR>\"])\n",
    "    print(char_index_rev[char_index[\"<UNK_CHAR>\"]])\n",
    "    return char_index,char_index_rev\n",
    "char_index,char_index_rev=add_unk_char(char_index,num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of chars: 1425\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of chars:\",len(char_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "3.878216578599242\n",
      "max_char_len_fit 7\n"
     ]
    }
   ],
   "source": [
    "max_char_len=-1\n",
    "for i in char:\n",
    "    if(len(i)>max_char_len):\n",
    "        max_char_len=len(i)\n",
    "print(max_char_len)\n",
    "avg_char_len=0\n",
    "for i in char:\n",
    "    avg_char_len+=len(i)\n",
    "avg_char_len=avg_char_len/len(char)\n",
    "print(avg_char_len)\n",
    "max_char_len=int(2*avg_char_len)\n",
    "print(\"max_char_len_fit\",max_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words: 68591\n",
      "No. of tags: 9\n",
      "51443\n"
     ]
    }
   ],
   "source": [
    "tokenizer_sent=Tokenizer()\n",
    "tokenizer_tags=Tokenizer()\n",
    "tokenizer_sent.fit_on_texts(sent)\n",
    "tokenizer_tags.fit_on_texts(tags)\n",
    "word_index_sent=tokenizer_sent.word_index\n",
    "word_index_tags=tokenizer_tags.word_index\n",
    "print(\"No. of words:\",len(word_index_sent))\n",
    "print(\"No. of tags:\",len(word_index_tags))\n",
    "num_words=(len(word_index_sent)*3)//4\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref={}\n",
    "for i,j in word_index_sent.items():\n",
    "    if(j<=num_words):\n",
    "        ref[i]=j\n",
    "ref[\"<UNK_WORD>\"]=num_words+1\n",
    "word_index_sent=ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_rev_sent={}\n",
    "word_index_rev_tags={}\n",
    "for i,j in word_index_sent.items():\n",
    "    word_index_rev_sent[j]=i\n",
    "for i,j in word_index_tags.items():\n",
    "    word_index_rev_tags[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char={}\n",
    "for i,j in word_index_sent.items():\n",
    "#     print(i,j)\n",
    "    l=[]\n",
    "    if(i==\"<UNK_WORD>\"):\n",
    "        l=[char_index[\"<UNK_CHAR>\"]]*max_char_len\n",
    "        word_char[i]=l\n",
    "#         print(l)\n",
    "        continue\n",
    "    for k in regex.findall(r'\\X',i):\n",
    "        if(k in char_index):\n",
    "#             print(k,end=\"-\")\n",
    "            h=char_index[k]\n",
    "        else:\n",
    "#             print(k)\n",
    "            h=char_index[\"<UNK_CHAR>\"]\n",
    "#         else:\n",
    "#             print(i)\n",
    "#             print(k,end=\"-\")\n",
    "#             h=char_index[\"<UNK_CHAR>\"]\n",
    "#             print(\"********\")\n",
    "#             print(\"------------------------------\")\n",
    "#             #         print(h)\n",
    "        l.append(h)\n",
    "    word_char[i]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char.items():\n",
    "#     print(i)\n",
    "# print(word_char[\"<UNK_WORD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in word_char.items():\n",
    "    word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51444\n",
      "('ಕೊಂಬು', array([175, 210,   0,   0,   0,   0,   0], dtype=int32))\n",
      "('ಮಾದರಿಗೆ', array([42,  2, 20, 50,  0,  0,  0], dtype=int32))\n",
      "('ಆರ್ಥ್ರೈಟಿಸ್', array([ 44,  13, 297, 265,  74,  18,   0], dtype=int32))\n",
      "('ದಿಲ್ಲಿಯಲ್ಲಿ', array([54,  4, 10,  3,  4, 10,  0], dtype=int32))\n",
      "('ಹನ್ನೆರಡನೆಯ', array([53, 11, 72,  1, 47, 72,  3], dtype=int32))\n",
      "('ಶೈಲ', array([321,  30,   0,   0,   0,   0,   0], dtype=int32))\n",
      "('ವಜ್ರಾಕಾರದಲ್ಲಿರುವ', array([45,  1,  2,  4, 10, 16,  5], dtype=int32))\n",
      "('ನುಡಿಯುತ್ತಾರೆ', array([28, 48, 76,  7, 78, 46,  0], dtype=int32))\n",
      "('ತಂಡಗಳಲ್ಲಿ', array([162,  47,   8,  24,   4,  10,   0], dtype=int32))\n",
      "('ರಾಯ್\\u200cಸೇನ್', array([ 31, 491, 161,  11,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_char={}\n",
    "# for i,j in word_index_sent.items():\n",
    "#     l=[]\n",
    "#     for k in regex.findall(r'\\X',i):\n",
    "#         if(k in char_index):\n",
    "#             l.append(char_index[k])\n",
    "#         else:\n",
    "#             l.append(char_index[\"<UNK_CHAR>\"])\n",
    "#     word_char[i]=l\n",
    "# for i,j in word_char.items():\n",
    "#     word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51444\n",
      "('ಕೊಂಬು', array([175, 210,   0,   0,   0,   0,   0], dtype=int32))\n",
      "('ಮಾದರಿಗೆ', array([42,  2, 20, 50,  0,  0,  0], dtype=int32))\n",
      "('ಆರ್ಥ್ರೈಟಿಸ್', array([ 44,  13, 297, 265,  74,  18,   0], dtype=int32))\n",
      "('ದಿಲ್ಲಿಯಲ್ಲಿ', array([54,  4, 10,  3,  4, 10,  0], dtype=int32))\n",
      "('ಹನ್ನೆರಡನೆಯ', array([53, 11, 72,  1, 47, 72,  3], dtype=int32))\n",
      "('ಶೈಲ', array([321,  30,   0,   0,   0,   0,   0], dtype=int32))\n",
      "('ವಜ್ರಾಕಾರದಲ್ಲಿರುವ', array([45,  1,  2,  4, 10, 16,  5], dtype=int32))\n",
      "('ನುಡಿಯುತ್ತಾರೆ', array([28, 48, 76,  7, 78, 46,  0], dtype=int32))\n",
      "('ತಂಡಗಳಲ್ಲಿ', array([162,  47,   8,  24,   4,  10,   0], dtype=int32))\n",
      "('ರಾಯ್\\u200cಸೇನ್', array([ 31, 491, 161,  11,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_int={}\n",
    "for i,j in word_char.items():\n",
    "    word_char_int[word_index_sent[i]]=j\n",
    "# for i in word_char_int.items():\n",
    "#     print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_embedding_matrix=np.zeros((len(word_char) + 1, max_char_len))\n",
    "for i,j in word_char_int.items():\n",
    "    word_char_embedding_matrix[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char_embedding_matrix:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51445, 50)\n"
     ]
    }
   ],
   "source": [
    "char_embedding_matrix = np.zeros((len(word_char) + 1, char_embedding_size))\n",
    "for i,j in char_index_rev.items():\n",
    "    if(j in c2v.wv.vocab):\n",
    "        char_embedding_matrix[i]=c2v.wv[j]\n",
    "print(char_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in char_embedding_matrix:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_int=[]\n",
    "for i in word_char_int.items():\n",
    "    char_int.append(i[1])\n",
    "# print(char_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datenum': 6,\n",
       " 'event': 8,\n",
       " 'location': 3,\n",
       " 'name': 2,\n",
       " 'number': 4,\n",
       " 'occupation': 5,\n",
       " 'organization': 7,\n",
       " 'other': 1,\n",
       " 'things': 9}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK_WORD>\n"
     ]
    }
   ],
   "source": [
    "# word_char[\"<UNK_WORD>\"]#array([2389, 2389, 2389, 2389, 2389], dtype=int32)\n",
    "# word_index_sent[\"<UNK_WORD>\"]#2389\n",
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j==\"<UNK_WORD>\"):\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int=[]\n",
    "for i in sent:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    sent_int.append(l)\n",
    "tags_int=[]\n",
    "for i in tags:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        l.append(word_index_tags[j])\n",
    "    tags_int.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int_padded=pad_sequences(sent_int,maxlen=max_len,padding='post')\n",
    "tags_int_padded=pad_sequences(tags_int,maxlen=max_len,padding=\"post\")\n",
    "# for i in tags_int_padded:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=100\n",
    "workers=5\n",
    "window_size=5\n",
    "word_min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sent:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51445, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v=Word2Vec(sent,size=embedding_size,workers=workers,window=window_size,min_count=word_min_count)\n",
    "embedding_matrix = np.zeros((len(word_index_sent) + 1, embedding_size))\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.69039822e+00  1.75935924e+00  7.89886527e-03 ... -2.01635289e+00\n",
      "   9.35428739e-01  9.63869393e-01]\n",
      " [ 2.18356848e+00  2.07963681e+00 -7.60598630e-02 ... -2.65754223e+00\n",
      "   1.02503645e+00 -4.74411309e-01]\n",
      " ...\n",
      " [ 3.98564991e-03  7.27030449e-04  2.29843287e-03 ... -2.77159573e-03\n",
      "   6.21093996e-03 -2.06276382e-04]\n",
      " [ 1.02102337e-03 -2.62002926e-03  1.61800918e-03 ...  1.97861344e-03\n",
      "   5.56464866e-03  8.42648442e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j in w2v.wv.vocab):\n",
    "        embedding_matrix[i]=w2v.wv[j]\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('location', 3)\n",
      "('organization', 7)\n",
      "('other', 1)\n",
      "('name', 2)\n",
      "('number', 4)\n",
      "('datenum', 6)\n",
      "('things', 9)\n",
      "('occupation', 5)\n",
      "('event', 8)\n",
      "{'location': array([0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'number': array([0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'other': array([1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'name': array([0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'organization': array([0., 0., 0., 0., 0., 0., 1., 0., 0.]), 'datenum': array([0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'things': array([0., 0., 0., 0., 0., 0., 0., 0., 1.]), 'occupation': array([0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'event': array([0., 0., 0., 0., 0., 0., 0., 1., 0.])}\n"
     ]
    }
   ],
   "source": [
    "tag_dir={}\n",
    "for i in word_index_tags.items():\n",
    "    print(i)\n",
    "    tag_dir[i[0]]=np.eye(len(word_index_rev_tags))[i[1]-1]\n",
    "print(tag_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18482, 28)\n"
     ]
    }
   ],
   "source": [
    "print(tags_int_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=[]\n",
    "count=0\n",
    "for i in tags_int_padded:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "#         print(j,end=\"____\")\n",
    "        if(j==0):\n",
    "            l.append(tag_dir[\"other\"])\n",
    "        else:\n",
    "            l.append(tag_dir[word_index_rev_tags[j]])\n",
    "    l=np.array(l)\n",
    "#     print(l.shape)\n",
    "#     print(count)\n",
    "    count+=1\n",
    "    tags_vec.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18482, 28)\n",
      "(18482, 28)\n",
      "(18482, 28, 9)\n",
      "['ಆದರೆ', 'ಮೇ', '೧೯೯೮ರಲ್ಲಿ', 'ಇತಿಯೋಪಿಯದೊಂದಿಗೆ', 'ಪುನಃ', 'ಯುದ್ಧ', 'ಪ್ರಾರಂಭವಾದುದರಿಂದ', 'ಈ', 'ಸಂವಿಧಾನ', 'ಕಾರ್ಯಕ್ಕೆ', 'ಬಂದಿಲ್ಲ', '.']\n",
      "['other', 'other', 'other', 'name', 'other', 'other', 'other', 'other', 'event', 'other', 'other', 'other']\n"
     ]
    }
   ],
   "source": [
    "print(sent_int_padded.shape)\n",
    "print(tags_int_padded.shape)\n",
    "print(np.array(tags_vec).shape)\n",
    "print(sent[0])\n",
    "\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=np.array(tags_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units=300\n",
    "from keras.layers import Embedding,InputLayer,Conv1D,MaxPooling1D,Input,Flatten,concatenate,merge,Reshape,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0=Input(shape=(max_len,))\n",
    "emb0=Embedding(len(word_index_sent)+1,max_char_len,weights=[word_char_embedding_matrix],trainable=False,input_length=max_len)(inputs0)\n",
    "emb01=TimeDistributed(Embedding(len(word_char)+1,char_embedding_size,weights=[char_embedding_matrix],trainable=False,input_length=max_char_len))(emb0)\n",
    "conv0=TimeDistributed(Conv1D(filters=20,kernel_size=5,padding=\"same\",activation=\"relu\"))(emb01)\n",
    "conv01=TimeDistributed(Conv1D(filters=11,kernel_size=5,padding=\"same\",activation=\"relu\"))(conv0)\n",
    "maxpool0=TimeDistributed(MaxPooling1D(pool_size=max_char_len))(conv01)\n",
    "# dropout0=TimeDistributed(Dropout(0.25))(maxpool0)\n",
    "newdim = tuple([x for x in maxpool0.shape.as_list() if x != 1 and x is not None])\n",
    "reshape0= Reshape(newdim) (maxpool0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_1/Reshape_1:0\", shape=(?, 28, 7, 50), dtype=float32)\n",
      "Tensor(\"time_distributed_2/Reshape_2:0\", shape=(?, 28, 7, 20), dtype=float32)\n",
      "Tensor(\"time_distributed_3/Reshape_2:0\", shape=(?, 28, 7, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(emb01)\n",
    "print(conv0)\n",
    "print(conv01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input(shape=(max_len,))\n",
    "emb1=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs1)          \n",
    "concat_0_1=concatenate([emb1,reshape0],axis=-1)\n",
    "conv1=Conv1D(filters=15,kernel_size=5,padding=\"same\",activation=\"relu\")(concat_0_1)\n",
    "# dropout1=Dropout(0.25)(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2=Input(shape=(max_len,))\n",
    "emb2=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs2)\n",
    "concat_1_2=concatenate([emb2,conv1],axis=-1)\n",
    "layers=Bidirectional(LSTM(units=num_hidden_units,input_shape=(max_len,embedding_size),return_sequences=True))(concat_1_2)\n",
    "# dropout2=Dropout(0.25)(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(len(word_index_tags),activation=\"softmax\"))(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inputs0,inputs1,inputs2],outputs=layers)\n",
    "model.compile(optimizer=\"adam\",metrics=[\"mae\",\"acc\"],loss=\"categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test=train_test_split(sent_int_padded,tags_vec,test_size=0.3,random_state=1)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "x_train=sent_int_padded\n",
    "y_train=tags_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 28, 7)        360115      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 28, 7, 50)    2572250     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 28, 7, 20)    5020        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 28, 7, 11)    1111        time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 28, 1, 11)    0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 28, 100)      5144500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 11)       0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 28)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 111)      0           embedding_3[0][0]                \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 28, 100)      5144500     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 28, 15)       8340        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 115)      0           embedding_4[0][0]                \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 28, 600)      998400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 28, 100)      60100       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 28, 100)      10100       time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 28, 9)        909         time_distributed_6[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 14,305,345\n",
      "Trainable params: 3,656,230\n",
      "Non-trainable params: 10,649,115\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png',show_shapes=True,show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "(None, 28)\n",
      "(None, 28)\n",
      "--------------------\n",
      "embedding_1\n",
      "(None, 28)\n",
      "(None, 28, 7)\n",
      "--------------------\n",
      "time_distributed_1\n",
      "(None, 28, 7)\n",
      "(None, 28, 7, 50)\n",
      "--------------------\n",
      "time_distributed_2\n",
      "(None, 28, 7, 50)\n",
      "(None, 28, 7, 20)\n",
      "--------------------\n",
      "time_distributed_3\n",
      "(None, 28, 7, 20)\n",
      "(None, 28, 7, 11)\n",
      "--------------------\n",
      "input_2\n",
      "(None, 28)\n",
      "(None, 28)\n",
      "--------------------\n",
      "time_distributed_4\n",
      "(None, 28, 7, 11)\n",
      "(None, 28, 1, 11)\n",
      "--------------------\n",
      "embedding_3\n",
      "(None, 28)\n",
      "(None, 28, 100)\n",
      "--------------------\n",
      "reshape_1\n",
      "(None, 28, 1, 11)\n",
      "(None, 28, 11)\n",
      "--------------------\n",
      "input_3\n",
      "(None, 28)\n",
      "(None, 28)\n",
      "--------------------\n",
      "concatenate_1\n",
      "[(None, 28, 100), (None, 28, 11)]\n",
      "(None, 28, 111)\n",
      "--------------------\n",
      "embedding_4\n",
      "(None, 28)\n",
      "(None, 28, 100)\n",
      "--------------------\n",
      "conv1d_3\n",
      "(None, 28, 111)\n",
      "(None, 28, 15)\n",
      "--------------------\n",
      "concatenate_2\n",
      "[(None, 28, 100), (None, 28, 15)]\n",
      "(None, 28, 115)\n",
      "--------------------\n",
      "bidirectional_1\n",
      "(None, 28, 115)\n",
      "(None, 28, 600)\n",
      "--------------------\n",
      "time_distributed_5\n",
      "(None, 28, 600)\n",
      "(None, 28, 100)\n",
      "--------------------\n",
      "time_distributed_6\n",
      "(None, 28, 100)\n",
      "(None, 28, 100)\n",
      "--------------------\n",
      "time_distributed_7\n",
      "(None, 28, 100)\n",
      "(None, 28, 9)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    print(i.name)\n",
    "    print(i.input_shape)\n",
    "    print(i.output_shape)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1425"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in y_train:\n",
    "# #     print(i)\n",
    "#     print(len(i))\n",
    "#     print(\"------------------\")\n",
    "len(char_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in x_train[:1000]:\n",
    "#     for j in i:\n",
    "#         if(j==0):\n",
    "#             break\n",
    "#         print(word_index_rev_sent[j],end=\"/\")\n",
    "#         l=[]\n",
    "#         for k in word_char_int[j]:\n",
    "#             if(k==0):\n",
    "#                 break\n",
    "#             l.append(char_index_rev[k])\n",
    "#         print(\"\".join(l),end=\" \")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14785 samples, validate on 3697 samples\n",
      "Epoch 1/25\n",
      "  190/14785 [..............................] - ETA: 7:36 - loss: 0.6739 - mean_absolute_error: 0.0476 - acc: 0.8835"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-895ee755e858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for i in range(epochs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n\u001b[0;32m----> 6\u001b[0;31m     EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "prev_loss=1\n",
    "loss_increase_warning=0\n",
    "# for i in range(epochs):\n",
    "his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n",
    "    EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_hindi_safe.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model_hindi_safe.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ner_kannada_safe_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### to predict load the new model along with the weights\n",
    "from keras.models import load_model\n",
    "model = load_model('ner_kannada_safe_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)==model2.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ans=model.predict([x_test,x_test,x_test])\n",
    "# c_other=0\n",
    "# i_other=0\n",
    "# c_non=0\n",
    "# i_non=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### to predict load the new model along with the weights\n",
    "# from keras.models import load_model\n",
    "# model = load_model('ner_kannada_safe_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in padded_x_test:\n",
    "    if(len(i)!=max_len):\n",
    "        print(i)\n",
    "# padded_x_test=np.array(padded_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.9234663490172722\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "incorrect=0\n",
    "for i in range(len(my_ans)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(pre_y_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j,k in zip(my_ans[i],pre_y_test[i]):\n",
    "        if(j==k):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "#     print(\"-----------------------------------------------------------------\")\n",
    "print(\"accuracy=\",(correct)/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26073   884   416   173   119    75    38    21     4]\n",
      " [  149   628    31     1    11     1     8     5     5]\n",
      " [  136    29   713     2    17     1     3     3     1]\n",
      " [   73     4     2   258     2     7     0     1     3]\n",
      " [   28     8     3     0   145     0     1     1     0]\n",
      " [   28     0     0     2     0    39     0     0     0]\n",
      " [    4     1     0     0     0     0    29     0     0]\n",
      " [    3     4     0     0     2     0     0    21     3]\n",
      " [    0     0     0     0     0     0     0     0     3]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix=np.zeros(shape=(len(word_index_rev_tags),len(word_index_rev_tags)),dtype=\"int32\")\n",
    "for i,j in zip(my_ans,pre_y_test):\n",
    "#     print(i)\n",
    "#     print(j)\n",
    "#     print(\"----------------\")\n",
    "    for ii,jj in zip(i,j):\n",
    "        x=word_index_tags[ii]\n",
    "        y=word_index_tags[jj]\n",
    "#         print(x,y)\n",
    "        confusion_matrix[x-1][y-1]+=1\n",
    "#         for i in confusion_matrix:\n",
    "#             print(i)\n",
    "#         print(\"-------------------\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word_index_rev_tags)):\n",
    "    print(word_index_rev_tags[i+1])\n",
    "    row_sum=0\n",
    "    col_sum=0\n",
    "    for j in range(len(word_index_rev_tags)):\n",
    "        row_sum+=confusion_matrix[i][j]\n",
    "        col_sum+=confusion_matrix[j][i]\n",
    "    p=confusion_matrix[i][i]/row_sum\n",
    "    r=confusion_matrix[i][i]/col_sum\n",
    "    f1=(2*p*r)/(p+r)\n",
    "    print(\"precision=\",p)\n",
    "    print(\"recall=\",r)\n",
    "    print(\"f1 score=\",f1)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_other=0\n",
    "i_other=0\n",
    "c_non=0\n",
    "i_non=0\n",
    "for i,j in zip(pre_y_test,my_ans):\n",
    "#     print(i,j)\n",
    "    for ii,jj in zip(i,j):\n",
    "#         print(x,y)\n",
    "        x=ii\n",
    "        y=jj\n",
    "        if(x==y):\n",
    "            if(x==\"other\"):\n",
    "                c_other+=1\n",
    "            else:\n",
    "                c_non+=1\n",
    "        elif(x!=y):\n",
    "            if(x==\"other\"):\n",
    "                i_other+=1\n",
    "            else:\n",
    "                i_non+=1\n",
    "#other accuracy\n",
    "print(\"other accuracy\")\n",
    "print(\"correct\",c_other)\n",
    "print(\"incorrect\",i_other)\n",
    "print(c_other/(c_other+i_other))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"non other accuracy\")\n",
    "print(\"correct\",c_non)\n",
    "print(\"incorrect\",i_non)\n",
    "print(c_non/(c_non+i_non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################final testing########################\n",
    "data_div=1\n",
    "pre_x_test=[]\n",
    "with codecs.open(\"v1_test1.kn\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    for i in f:\n",
    "        i=i.strip()\n",
    "        if(i==\"newline\"):\n",
    "            pre_x_test.append(l1)\n",
    "#             print(len(pre_x_test))\n",
    "            l1=[]\n",
    "        else:\n",
    "            l1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl=open(\"q1.kn\",\"w\")\n",
    "for i in range(len(pre_x_test)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        fl.write(my_ans[i][j]+\"\\n\")\n",
    "    fl.write(\"newline\\n\")\n",
    "#     print(\"---------------------\")\n",
    "fl.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
