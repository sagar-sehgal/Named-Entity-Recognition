{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D\n",
    "from keras.models import Sequential,Model\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Bidirectional,TimeDistributed\n",
    "import numpy as np\n",
    "import codecs\n",
    "import regex\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_div=1\n",
    "sent=[]\n",
    "tags=[]\n",
    "with codecs.open(\"v1_train.ta\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in f:\n",
    "        x=i.split()\n",
    "        if(x[0]==\"newline\"):\n",
    "            sent.append(l1)\n",
    "            tags.append(l2)\n",
    "            l1=[]\n",
    "            l2=[]\n",
    "        else:\n",
    "            l1.append(x[0])\n",
    "            l2.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134030\n",
      "382876\n",
      "{'location': 134262, 'things': 6183, 'datenum': 15482, 'other': 1109354, 'occupation': 16507, 'event': 5112, 'number': 77310, 'name': 118021, 'organization': 9999}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(sent))\n",
    "tag_count=0\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        if(j!=\"other\"):\n",
    "            tag_count+=1\n",
    "print(tag_count)\n",
    "tag_map={'datenum': 0,\n",
    " 'event': 0,\n",
    " 'location': 0,\n",
    " 'name': 0,\n",
    " 'number': 0,\n",
    " 'occupation': 0,\n",
    " 'organization': 0,\n",
    " 'other': 0,\n",
    " 'things': 0}\n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        tag_map[j]+=1\n",
    "print(tag_map)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120627\n",
      "120627\n",
      "13403\n",
      "13403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sent,pre_x_test,tags,pre_y_test=train_test_split(sent,tags,test_size=0.1,random_state=1)\n",
    "print(len(sent))\n",
    "print(len(tags))\n",
    "print(len(pre_x_test))\n",
    "print(len(pre_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 13944\n",
      "1 : 18442\n",
      "2 : 28607\n",
      "3 : 24909\n",
      "4 : 12169\n",
      "5 : 11453\n",
      "6 : 3890\n",
      "7 : 2432\n",
      "8 : 1579\n",
      "9 : 1272\n",
      "10 : 665\n",
      "11 : 416\n",
      "12 : 247\n",
      "13 : 170\n",
      "14 : 125\n",
      "15 : 87\n",
      "16 : 61\n",
      "17 : 45\n",
      "18 : 29\n",
      "19 : 21\n",
      "20 : 15\n",
      "21 : 10\n",
      "22 : 3\n",
      "23 : 7\n",
      "24 : 4\n",
      "25 : 5\n",
      "26 : 1\n",
      "27 : 3\n",
      "28 : 2\n",
      "29 : 1\n",
      "30 : 2\n",
      "31 : 3\n",
      "33 : 2\n",
      "34 : 2\n",
      "35 : 1\n",
      "37 : 1\n",
      "38 : 1\n",
      "39 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcnWV9///Xe2Yyk2Qm+wwhJIEkEArByuKwKKgUWQL1W2ixfqFa0fITq1i1P2sF67dal99PbYW6YlEQaBXEhUIpFYGiSCVAwhZIWMYJS2KWyb4vM/P5/nFfJzkMs5xMzjJn5v18cD/OfV/nXj7nHnI+577u+7ouRQRmZmbFUFPpAMzMbPhwUjEzs6JxUjEzs6JxUjEzs6JxUjEzs6JxUjEzs6IpWVKRNFrSI5KelPSMpH9I5bMlPSypTdKPJNWn8oa03Jben5W3rytT+XOSzskrn5/K2iRdUarPYmZmhSnllcou4IyIOBY4Dpgv6RTgy8DVEXEEsAG4NK1/KbAhlV+d1kPSPOAi4BhgPvBtSbWSaoFvAecC84CL07pmZlYhJUsqkdmaFkelKYAzgJ+k8huBC9L8+WmZ9P7bJCmV3xIRuyJiGdAGnJSmtohoj4jdwC1pXTMzq5C6Uu48XU0sAo4gu6r4LbAxIjrTKsuB6Wl+OvAKQER0StoETEnlC/J2m7/NKz3KTx4opubm5pg1a9ZgPo6Z2Yi1aNGitRHRMtB6JU0qEdEFHCdpInAbcFQpj9cXSZcBlwEceuihLFy4sBJhmJlVLUkvFbJeWZ7+ioiNwP3AG4GJknLJbAawIs2vAGYCpPcnAOvyy3ts01d5b8e/NiJaI6K1pWXARGtmZoNUyqe/WtIVCpLGAGcBS8mSyzvSapcAt6f5O9Iy6f3/jqy3yzuAi9LTYbOBucAjwKPA3PQ0WT3Zzfw7SvV5zMxsYKWs/poG3Jjuq9QAt0bEnZKWALdI+gLwOHBdWv864F8ltQHryZIEEfGMpFuBJUAncHmqVkPSh4G7gVrg+oh4poSfx8zMBqCR1vV9a2tr+J6Kmdn+kbQoIloHWs8t6s3MrGicVMzMrGicVMzMrGicVMqgqzu4+ZGX2dXZVelQzMxKykmlDB5Ztp4rf7aY2x7rtRmNmdmw4aRSBis27gDg3qVrKhyJmVlpOamUwapNWVJ5sK2DHbtdBWZmw5eTShn8btNOAHbu6eZ/2tZWOBozs9JxUimDVZt2cuTUJsY11HHPktWVDsfMrGRK2kuxZX63cQeHTh7L7x08nvueXU13d1BTo0qHZWZWdL5SKYNVm3dy8ITRnHn0Qazdupsnlm+sdEhmZiXhpFJiO3Z3sXH7HqZNGMPpRx5EXY2411VgZjZMOamU2Mr05Ne0CaOZMHYUJ82ezL1LnVTMbHhyUimxVenJr4MnjAbgzKOn8vzqrby0blslwzIzKwknlRLLPU58yIQxAJw1byqAnwIzs2HJSaXEcg0fc1cqMyeP5aiDx7kKzMyGJSeVEvvdpp1Mbqxn9KjavWVnHj2VR1/cwMbtuysYmZlZ8TmplNiqTTs5ePzoV5WdOW8qXd3BL5/rqFBUZmal4aRSYis37eSQia9OKq+fPoGWcQ3c4yowMxtmnFRKbOWmHXvvp+TU1Igzjz6IXz3X4TFWzGxYcVIpofyGjz2defRUtu7q5OH29RWIzMysNJxUSii/4WNPpx7RzJhRtX4KzMyGFSeVEurZ8DHf6FG1vHluM/cuWU1ElDs0M7OScFIpoZ4NH3s6c95UfrdpJ0tWbi5nWGZmJeOkUkI9Gz72dMZRByG5db2ZDR9OKiXUW8PHfM1NDZxw6CTfVzGzYaNkSUXSTEn3S1oi6RlJH03ln5W0QtITaTovb5srJbVJek7SOXnl81NZm6Qr8spnS3o4lf9IUn2pPs9g9Nbwsaczj57K0ys2772pb2ZWzUp5pdIJfDwi5gGnAJdLmpfeuzoijkvTXQDpvYuAY4D5wLcl1UqqBb4FnAvMAy7O28+X076OADYAl5bw8+y33ho+9pTrYPLepWvKEZKZWUmVLKlExMqIeCzNbwGWAtP72eR84JaI2BURy4A24KQ0tUVEe0TsBm4Bzpck4AzgJ2n7G4ELSvNpBqe3ho89Hd7SyOzmRg/cZWbDQlnuqUiaBRwPPJyKPizpKUnXS5qUyqYDr+RttjyV9VU+BdgYEZ09yns7/mWSFkpa2NFRnv62+mv42CM2zjz6IB767Tp27HbrejOrbiVPKpKagJ8CH4uIzcA1wOHAccBK4KuljiEiro2I1ohobWlpKfXhgP4bPvZ09LTx7O7qZtXmnaUOy8yspEqaVCSNIksoP4iInwFExOqI6IqIbuC7ZNVbACuAmXmbz0hlfZWvAyZKqutRPiT01/Cxp+amBgDWbt1V0pjMzEqtlE9/CbgOWBoRV+WVT8tb7Y+Bp9P8HcBFkhokzQbmAo8AjwJz05Ne9WQ38++IrBn6/cA70vaXALeX6vPsr4EaPuab0pQ9tLZ2i5OKmVW3uoFXGbRTgT8HFkt6IpV9iuzpreOAAF4EPgAQEc9IuhVYQvbk2OUR0QUg6cPA3UAtcH1EPJP290ngFklfAB4nS2JDwkANH/O15K5UtnnQLjOrbiVLKhHxIKBe3rqrn22+CHyxl/K7etsuItrZV302pKwcoOFjvsmNvlIxs+HBLepLZGUBDR9z6mprmDR2lO+pmFnVc1IpkUIaPuZrbmpg3VZXf5lZdXNSKZFCGj7ma25q8JWKmVU9J5USKLThY74pTfVOKmZW9ZxUSmB/Gj7muPrLzIYDJ5US2J+Gjzkt4xrYsquTnXvcVYuZVS8nlRLYn4aPOVNyjxW7CszMqpiTSgnsT8PHnH1dtbgKzMyql5NKCexPw8ec5nFZUlnnKxUzq2JOKiWwPw0fc5qbXP1lZtXPSaUE9rfhI7j6y8yGByeVEtjfho8Ao0fV0tRQ5ysVM6tqTipFNpiGjznNTfW+UjGzquakUmSDafiYM6WpwT0Vm1lVc1IpssE0fMxpbqpn3TYnFTOrXk4qRbZyEA0fc7JOJV39ZWbVy0mlyFYOouFjzpSmBjZs301nV3exwzIzKwsnlSIbTMPHnJameiJg/XZfrZhZdXJSKbLBNHzM2dtWZYuTiplVJyeVIlu5aeegnvyCrPoL3KrezKqXk0qRrdy0g2n72Zo+J9dVi58AM7Nq5aRSRAfS8BH2dSrp6i8zq1ZOKkV0IA0fAcY11FFfV+PqLzOrWk4qRXQgDR8BJNHcWE+Hk4qZVSknlSI6kIaPOc3jPFa9mVWvkiUVSTMl3S9piaRnJH00lU+WdI+kF9LrpFQuSV+X1CbpKUkn5O3rkrT+C5IuySt/g6TFaZuvS1KpPk8hDqThY07Wqt5XKmZWnUp5pdIJfDwi5gGnAJdLmgdcAdwXEXOB+9IywLnA3DRdBlwDWRICPgOcDJwEfCaXiNI678/bbn4JP8+ADqThY86UxnonFTOrWiVLKhGxMiIeS/NbgKXAdOB84Ma02o3ABWn+fOCmyCwAJkqaBpwD3BMR6yNiA3APMD+9Nz4iFkREADfl7asiDqThY06u+iv7SGZm1aUs91QkzQKOBx4GpkbEyvTWKmBqmp8OvJK32fJU1l/58l7KK+ZAGj7mNDc10NkdbNqxp0hRmZmVz4BJRdJXJI2XNErSfZI6JL270ANIagJ+CnwsIjbnv5euMEr+k1zSZZIWSlrY0dFRsuMcSMPHHI9Vb2bVrJArlbNTMng78CJwBPCJQnYuaRRZQvlBRPwsFa9OVVek1zWpfAUwM2/zGamsv/IZvZS/RkRcGxGtEdHa0tJSSOj77UAbPuZ4rHozq2aFJJW69PqHwI8jYlMhO05PYl0HLI2Iq/LeugPIPcF1CXB7Xvl70lNgpwCbUjXZ3cDZkialG/RnA3en9zZLOiUd6z15+yq7VZuzx4mLUf0FvlIxs+pUN/Aq3CnpWWAH8EFJLcDOArY7FfhzYLGkJ1LZp4AvAbdKuhR4CXhneu8u4DygDdgOvA8gItZL+jzwaFrvcxGxPs1/CLgBGAP8V5oqYuXGA3+cGGBKrvrLwwqbWRUaMKlExBWSvkJ25dAlaTvZk1oDbfcg0Fe7kbf1sn4Al/exr+uB63spXwi8bqBYyqEYDR8BJo2tp0awbpurv8ys+hRyo34s2RXBNanoEKC1lEFVo2I0fASorRGTG90A0syqUyH3VL4P7AbelJZXAF8oWURVqhgNH3Oam+rpcE/FZlaFCkkqh0fEV4A9ABGxnb6rtUasYjR8zHFXLWZWrQpJKrsljSG1J5F0OOBvvB6K0fAxp7mp3gN1mVlVKiSpfAb4OTBT0g/I+uv625JGVYWK0fAxp7mpwQN1mVlVKuTpr3skPUbWKaSAj0bE2pJHVkU2bd/Dxu17OGTigT35lTOlqYEde7rYtquTxoZCnvo2MxsaCnn664+Bzoj4z4i4E+iUVNGOG4eaR17Mms20Hja5KPvbO1a9W9WbWZUpqPorvxV9RGwkqxKz5KHfrqOhroZjZ04oyv5yY9V7BEgzqzaFJJXe1nGdTJ4F7et4w2GTaKg78MeJAZob3VWLmVWnQpLKQklXSTo8TVcBi0odWLXYuH03S1dt5o1zphRtn83jXP1lZtWpkKTyV2SNH3+Upl300Z3KSPTwsvVEwCmHFy+pTPGViplVqUKe/trGviF/rYcF7esYPaqG188ozv0UgPq6GsaPrnNSMbOqM2BSkXQk8DfArPz1I+KM0oVVPRa0ry/q/ZSc3LDCZmbVpJAb7j8GvgN8D+gqbTjVZcO23SxduZm/OfvIou+7uanBT3+ZWdUpJKl0RsQ1A6828jy8LGufckoRb9LntDQ1sHTV5oFXNDMbQgq5Uf8fkj4kaZqkybmp5JFVgX33UyYWfd9Tmupd/WVmVaeQK5Xc0L/549IHMKf44VSXBe3raD1sMvV1heTm/dPc1MCmHXvY3dldkv2bmZVCIU9/zS5HINVm/bbdPLtqC58455CS7D83Vv26bbuYdoCjSZqZlUtBIz9K+rSka9PyXElvL31oQ9sjy9YBcMqc0tQE7hur3lVgZlY9PPLjIC1oX8+YUbX8/vTi30+BfVcqaz2uiplVEY/8OEgP/XYdrbMmlex+R0suqWxxUjGz6uGRHwdh3dZdPLd6S0keJc7ZW/3lJ8DMrIoU8vTXZ3n1yI+nAu8rZVBD3SMlbJ+S09hQx5hRtaxzA0gzqyKFPP31C0mL8MiPey1oX8fY+tqi9vfVm+Zx9e7/y8yqSiFPf90XEetyIz9GxFpJ95UjuKHqofZ1tM6azKja0rYfmdLY4OovM6sqfV6pSBoNjAWaJU1i38358cD0MsQ2JK3duovnV2/lguNLfwqamxpYvmF7yY9jZlYs/f3U/gDZYFxHpdfcdDvwzYF2LOl6SWskPZ1X9llJKyQ9kabz8t67UlKbpOcknZNXPj+VtUm6Iq98tqSHU/mPJNXvzwcfrHLcT8lpGVfvKxUzqyp9JpWI+FpqTf83ETEnIman6diIGDCpADcA83spvzoijkvTXQCS5gEXAcekbb4tqVZSLfAt4FxgHnBxWhfgy2lfRwAbgEsL+sQH6KHfZvdTfn96ae+nQHalsn7bLrq6o+THMjMrhkJu1H9D0pt47XgqNw2w3QOSZhUYx/nALRGxC1gmqQ04Kb3XFhHtAJJuAc6XtBQ4A/iztM6NZE+plbw35QXt6zixDPdTAKY01tMd2ZDFU1K7FTOzoayQG/X/CvwTcBpwYppaD+CYH5b0VKoem5TKpgOv5K2zPJX1VT4F2BgRnT3K+/oMl0laKGlhR0fHoANfu3UXL6zZWpaqL8gG6sqO6yowM6sOhbRTaQXmRUQx6mCuAT5P1pDy88BXgb8own77FRHXAtcCtLa2DvpzPNyeu59Snp7/93bVsnUXv8e4shzTzOxAFFKH8zRwcDEOFhGrI6IrIrqB77KvimsFMDNv1RmprK/ydcBESXU9ykvqofa1NNbX8roy3E8BaN7bqt5tVcysOhSSVJqBJZLulnRHbhrMwSRNy1v8Y7KEBXAHcJGkBkmzgbnAI8CjwNz0pFc92c38O9JV0/3AO9L2l5A9lVZSC9rXc+Ls8txPgfwrFVd/mVl1KLSblv0m6WbgdLJ2LsuBzwCnSzqOrPrrRbLHlomIZyTdCiwBOoHLI6Ir7efDwN1ALXB9RDyTDvFJ4BZJXwAeB64bTJyF6tiyi7Y1W3nHG2aU8jCvMmHMKOpq5CsVM6sahTz99StJhwFzI+JeSWPJvuAH2u7iXor7/OKPiC8CX+yl/C7grl7K29lXfVZyC9pz46eU5yY9gCSmNNW7p2IzqxqFPP31fuAnwL+kounAv5cyqKFoQfs6mhrqeN0h48t63OamBtZtc/WXmVWHQm4OXE7WM/FmgIh4ATiolEENRVn7lEnUlel+Sk5zU4Orv8ysahRyT2VXROyWsq6/0hNXI66J95cufD01Kv/YZFOa6nlh9ZayH9fMbDAKSSq/kvQpYIyks4APAf9R2rCGnhNnladtSk8tTQ2s3babiEAVSGpmZvujkLqcK4AOYDHZ01p3AZ8uZVC2T3NTA7s7u9myq3Pglc3MKqyQp79yDRW/K2kyMKNIreutAM3jUgPILbsYP3pUhaMxM+tfIU9//VLS+JRQFpEll6tLH5pBNlAX4CfAzKwqFFL9NSEiNgN/AtwUEScDbyttWJazt1W926qYWRUoJKnUpe5V3gncWeJ4rIe91V9+rNjMqkAhSeVzZN2ktEXEo5LmAC+UNizLmTy2Hsn9f5lZdSjkRv2PgR/nLbcDF5YyKNunrraGSWPrfaViZlWhvM3DbVCam5xUzKw6OKlUgSmNDaxz9ZeZVYE+k4qkj6bXU8sXjvWmZVwDbR1beWr5xkqHYmbWr/6uVN6XXr9RjkCsb+87dRb1tTVc8K3/4fN3LmGbW9eb2RDVX1JZKukF4PckPZU3LZb0VLkCNDj+0Enc+/G38mcnH8p1Dy7j7Ksf4P5n11Q6LDOz11B/Pa5IOpjsceI/6vleRLxUwrhKprW1NRYuXFjpMAZt4YvrufJni3lhzVb+17GH8Pdvn0fLuIZKh2Vmw5ykRRHROtB6/d6oj4hVEXEssBIYl6bfVWtCGQ5aZ03mzo+cxv971pHc/fQq3vbVX/KjR1/G3bGZ2VBQSN9fbyVr7Pgt4NvA85LeUurArG8NdbV85G1z+a+PvZmjpo3nkz9dzJd//lylwzIzK+iR4quAsyPirRHxFuAcwB1KDgGHtzRxy/tP4eTZk3mwraPS4ZiZFZRURkXE3p/BEfE84D7Yh4iaGnH0tPEs69jmKjAzq7hCRn5cKOl7wL+l5XcB1Xunexia09LItt1drNmyi6njR1c6HDMbwQq5UvkgsAT4SJqWpDIbImY3NwLQ3rGtwpGY2UhXSIeSu8juq1xV+nBsMOa0NAGwbO023nj4lApHY2Yjmfv+GgamjR9NQ10Ny9ZurXQoZjbClSypSLpe0hpJT+eVTZZ0j6QX0uukVC5JX5fUllrtn5C3zSVp/RckXZJX/obUur8tbatSfZahrqZGzG5udPWXmVVcKa9UbgDm9yi7ArgvIuYC96VlgHOBuWm6DLgGsiQEfAY4GTgJ+EwuEaV13p+3Xc9jjSizmxtZttZJxcwqa1BJRdJlA60TEQ8A63sUnw/cmOZvBC7IK78pMguAiWkI43OAeyJifURsAO4B5qf3xkfEgsieo70pb18j0pyWRl5ev509Xd2VDsXMRrDBXqkMtqppakSsTPOrgKlpfjrwSt56y1NZf+XLeykfsWY3N9HZHSzfsKPSoZjZCDaopBIR/3KgB05XGGVprSfpMkkLJS3s6BieLc/3PVbsm/VmVjmF9P01QdLVuS9lSV+VNGGQx1udqq5Ir7n+21cAM/PWm5HK+iuf0Ut5ryLi2ohojYjWlpaWQYY+tM1JScX3Vcyskgq5Urke2Ay8M02bge8P8nh3ALknuC4Bbs8rf096CuwUYFOqJrsbOFvSpHSD/mzg7vTeZkmnpKe+3pO3rxFpUmM9E8eOot1JxcwqqJBuWg6PiAvzlv9B0hMDbSTpZuB0oFnScrKnuL4E3CrpUuAlsiQFcBdwHtAGbCeNOhkR6yV9Hng0rfe5iMjd/P8Q2RNmY4D/StOINqe5kWV+rNjMKqiQpLJD0mkR8SDsHbN+wLvBEXFxH2+9rZd1A7i8j/1cT3a11LN8IfC6geIYSWY3N7m3YjOrqEKSyl8CN6X7KCJ7TPi9pQzKBmdOSyM/fWw523Z10thQyJ/WzKy4Cun760ngWEnj0/LmkkdlgzI772b966YP9lkKM7PBGzCpSGoALgRmAXW53lAi4nMljcz225wWJxUzq6xC6khuBzYBi4BdpQ3HDsSsKe4C38wqq5CkMiMiRnS/WtVi9Khapk8c496KzaxiCmmn8htJv1/ySKwo3LGkmVVSIUnlNGCRpOdSt/SLJT1V6sBscOa0NNK+1uPVm1llFFL9dW7Jo7Cimd3cyJadnazdupuWcQ2VDsfMRphCHil+qRyBWHHkP1bspGJm5ebhhIeZOc258ep9s97Mys9JZZiZPmkM9bU17ljSzCrCSWWYqa0Rh00Z67YqZlYRTirDkB8rNrNKcVIZhma3NPLSum10dfuxYjMrLyeVYWhOcyN7uoIVHq/ezMrMSWUYmtOSPQHW7ifAzKzMnFSGoVxbFd+sN7Nyc1IZhqY01jNudJ1v1ptZ2TmpDEOSsvHqnVTMrMycVIapOS1NTipmVnZOKsPU7OZGVmzcwY7dXZUOxcxGECeVYSp3s/7Fdb5aMbPycVIZpvJ7KzYzKxcnlWHKScXMKsFJZZhqbKjj4PGj+W2HG0CaWfk4qQxj7ljSzMqtIklF0otprPsnJC1MZZMl3SPphfQ6KZVL0tcltUl6StIJefu5JK3/gqRLKvFZhrLZLU4qZlZelbxS+YOIOC4iWtPyFcB9ETEXuC8tA5wLzE3TZcA1kCUh4DPAycBJwGdyicgyc5ob2bh9Dxu27a50KGY2Qgyl6q/zgRvT/I3ABXnlN0VmATBR0jTgHOCeiFgfERuAe4D55Q56KJvTkvoAc8eSZlYmlUoqAfxC0iJJl6WyqRGxMs2vAqam+enAK3nbLk9lfZW/hqTLJC2UtLCjo6NYn2HIm53Gq3fHkmZWLnUVOu5pEbFC0kHAPZKezX8zIkJS0UaYiohrgWsBWltbR8zIVTMmjaGuRr6vYmZlU5ErlYhYkV7XALeR3RNZnaq1SK9r0uorgJl5m89IZX2VWzKqtoZDJ491UjGzsil7UpHUKGlcbh44G3gauAPIPcF1CXB7mr8DeE96CuwUYFOqJrsbOFvSpHSD/uxUZnnmtDS6+svMyqYS1V9Tgdsk5Y7/w4j4uaRHgVslXQq8BLwzrX8XcB7QBmwH3gcQEeslfR54NK33uYhYX76PUR1mNzfywAtr6e4OampU6XDMbJgre1KJiHbg2F7K1wFv66U8gMv72Nf1wPXFjnE4md3cxO7Obn63aQczJo2tdDhmNswNpUeKrQTcB5iZlZOTyjCXa6vy3KotFY7EzEYCJ5Vh7qBxDbxu+ni+eX8br6zfXulwzGyYc1IZ5iTxzYtPoKs7+NAPHmPnHo8EaWal46QyAsxqbuSrf3osi1ds4nN3Lql0OGY2jDmpjBBnH3MwHzz9cH748Mv8ZNHySodjZsOUk8oI8vGzjuSNc6bwd7ctZsnvNlc6HDMbhpxURpC62hq+fvHxTBw7ig/+YBGbduypdEhmNsw4qYwwLeMa+NafncCKDTv4+K1P0t09YvrXNLMycFIZgVpnTeZT5x3NvUtX850HflvpcMxsGHFSGaHed+os3v76afzT3c/xm7a1lQ7HzIYJJ5URShJfvvD1zGlp4q9ufpy2NR4d0swOnJPKCNbYUMd33n0CAfzRNx/k9ic8HI2ZHRgnlRHuiIPG8Z8fOY1jDhnPR295gk/dttit7s1s0JxUjGkTxvDD95/CB946hx8+/DJ/8u3f8KJ7NTazQXBSMSAbevjKc4/muktaWbFxB2//xoPctXhlpcMysyrjpGKv8rajp3LXR9/M3KlNfOgHj/HZO55hV6erw8ysMJUYTtiGuOkTx/Cjy97Il3/+LNc9uIwF7ev4kxOmc9oRLRw9bRxpKGgzs9dwUrFe1dfV8H/ePo+TZk/mql88z/9317PAszQ3NfDmuc2cdkQzb57bzEHjR1c6VDMbQpxUrF/nHHMw5xxzMKs27eTBtrX8+oUOHni+g9sezx4//r2p4zjnmKlcetocJowdVeFozazSFDGy+n5qbW2NhQsXVjqMqtbdHSxdtZlfv7CWB57v4KH2dYxrqONDf3AE733TLEaPqq10iGZWZJIWRUTrgOs5qdiBWrpyM1/5+bPc/1wHB48fzV+fNZcLT5hBXa2fAzEbLgpNKv5Xbwfs6Gnj+f77TuLm95/C1Amj+eRPFzP/a7/m7mdWMdJ+tJiNdE4qVjRvPHwK//6hN/Gdd59Ad3fwgX9dxIXX/Ib/fGolqzfvrHR4ZlYGrv6ykujs6ubHi5bzz/c+z+rNuwA4ZMJojj9sEsfPnMgJh03imEPG01Dn+y9m1cD3VPrgpFJeuzu7WbJyM4+9tIHHX9nIYy9tYMXGHQDU19ZwzPTxHHXwOGY3NzKnuYnZLY3MnDSW+jpfRJsNJYUmlap/pFjSfOBrQC3wvYj4UoVDsjz1dTUcN3Mix82cuLdszeadPPbyRh5/ZQOPv7yRXzyzmnXbdu99v7ZGzJw0hjktTRw2ZSzNTQ1MGDOKCWNGMXFseh1Tz4Qxoxg3uo6aGjfGNBsqqvpKRVIt8DxwFrAceBS4OCKW9LWNr1SGpk3b99C+divL1m5j2dpttHdso33tNl5at43tu/vvJmb0qBrG1tcxZlQto0fVMKa+Ns1nrw2jahldV8Po9H5DXfY6elQt9XU1jKrNTXrNfF2NqKsVNRJ1NTXUvmpZ1KaprkbU9HxVboIaCQn3RmBVa6RcqZwEtEVEO4CkW4DzgT6Tig1NE8aO4vhDJ3H8oZNe897OPV1s3rGHTTv2sHHQAw7JAAAL0ElEQVTHHjZtT69p2rmnix27u9ixJ027s2nLzk46tuxiV2c3O/d0sXNP19757gr9lpJAsDfhkLesXPIByE9EZMlIue3z5mv2zu/bviatExEEkPvdGAQR+5Zz8bzqFbE/eS8/NvJiBfY++bf3cP2dc/W72G8y7vnDOPpcKNAAn39/fxb0jL2SPyvu/MhpJb+PWe1JZTrwSt7ycuDknitJugy4DODQQw8tT2RWNKPTVUexuoSJCDq7g517utjd2c2ermBPV3easvndXd3s7uymuztbtytNnXtfu/eWdXUHXRGvWs6tF5F9kXcHdEe23B3ZF3xXd/aa/qO7O0sC3ZH78t+XFPYmhNxybh3S/vLW707H2JuE2PfFtu/LX9mxgfyX/EQw0Jffvtj2HZsUk9ibpfJfek0O/SaFXgpetf+cfhb35+pwoJqb/c5RvcReSa85byVQ7UmlIBFxLXAtZNVfFQ7HKkzS3uotMyuuav9XtQKYmbc8I5WZmVkFVHtSeRSYK2m2pHrgIuCOCsdkZjZiVXX1V0R0SvowcDfZI8XXR8QzFQ7LzGzEquqkAhARdwF3VToOMzOr/uovMzMbQpxUzMysaJxUzMysaJxUzMysaKq676/BkNQBvDTIzZuBtUUMp5gc2+A4tsFxbINTzbEdFhEtA+1kxCWVAyFpYSEdqlWCYxscxzY4jm1wRkJsrv4yM7OicVIxM7OicVLZP9dWOoB+OLbBcWyD49gGZ9jH5nsqZmZWNL5SMTOzonFSKYCk+ZKek9Qm6YpKx9OTpBclLZb0hKSKjpUs6XpJayQ9nVc2WdI9kl5Ir68d3rFysX1W0op07p6QdF4F4pop6X5JSyQ9I+mjqbzi562f2Cp+3lIcoyU9IunJFN8/pPLZkh5O/2Z/lHoxHwpx3SBpWd55O66ccfWIsVbS45LuTMtFOWdOKgOQVAt8CzgXmAdcLGleZaPq1R9ExHFD4HHFG4D5PcquAO6LiLnAfWm5Em7gtbEBXJ3O3XGpg9Jy6wQ+HhHzgFOAy9P/Y0PhvPUVG1T+vAHsAs6IiGOB44D5kk4BvpziOwLYAFw6ROIC+ETeeXuizHHl+yiwNG+5KOfMSWVgJwFtEdEeEbuBW4DzKxzTkBURDwDrexSfD9yY5m8ELihrUEkfsVVcRKyMiMfS/Bayf+jTGQLnrZ/YhoTIbE2Lo9IUwBnAT1J52c9dP3ENCZJmAH8IfC8tiyKdMyeVgU0HXslbXs4Q+keVBPALSYskXVbpYHoxNSJWpvlVwNRKBtOLD0t6KlWPVaRqLkfSLOB44GGG2HnrERsMkfOWqnGeANYA9wC/BTZGRGdapSL/ZnvGFRG58/bFdN6ultRQ7riSfwb+FuhOy1Mo0jlzUhkeTouIE8iq6C6X9JZKB9SXyB43HDK/2IBrgMPJqihWAl+tVCCSmoCfAh+LiM3571X6vPUS25A5bxHRFRHHkQ0nfhJwVKViydczLkmvA64ki+9EYDLwyXLHJentwJqIWFSK/TupDGwFMDNveUYqGzIiYkV6XQPcRvYPayhZLWkaQHpdU+F49oqI1ekffzfwXSp07iSNIvvS/kFE/CwVD4nz1ltsQ+W85YuIjcD9wBuBiZJygxBW9N9sXlzzU3ViRMQu4PtU5rydCvyRpBfJqvPPAL5Gkc6Zk8rAHgXmpicj6oGLgDsqHNNekholjcvNA2cDT/e/VdndAVyS5i8Bbq9gLK+S+9JO/pgKnLtUn30dsDQirsp7q+Lnra/YhsJ5S3G0SJqY5scAZ5Hd97kfeEdareznro+4ns37kSCyexZlP28RcWVEzIiIWWTfZ/8dEe+iWOcsIjwNMAHnAc+T1dX+XaXj6RHbHODJND1T6fiAm8mqQ/aQ1cteSlZfex/wAnAvMHkIxfavwGLgKbIv8WkViOs0sqqtp4An0nTeUDhv/cRW8fOW4ns98HiK42ng71P5HOARoA34MdAwROL673Tengb+DWiqxHnLi/N04M5injO3qDczs6Jx9ZeZmRWNk4qZmRWNk4qZmRWNk4qZmRWNk4qZmRWNk4pVlKSbU5cVf13hOGZJ+rO85fdK+mYR939BqTsilfS9/TmGpNMlvSlv+QZJ7+hvm1Lr+Xew6uOkYhUj6WDgxIh4fURcXeFwZgFF+zJLvVvnu4Csl+uSiYj/JyKW7McmpwNvGmilMptFEf8OVn5OKtar9ItxqaTvpvEgfpFaBiPpOEkL0hXGbQN1JpjGlvi+sjFfHpf0B+mtXwDT07gSb+6xzQ2Svi7pN5Lac7+glflHSU+n/f3vVH66pF9K+omkZyX9ILVa7hlLr9sDXwLenGLJXTUdIunnysYz+UrePs6W9JCkxyT9OPWLlRvX5suSHgP+NG/9NwF/BPxj2v/hkt4v6VFl4238VNLYtO7h6dwulvQFSVtT+TRJD6Ttn+55vtI6v5TUmua3Svpi2v8CSVN7rDsL+Evgr3uc/7f0POdp/U+keJ9SGhukx/5q098sd17/Ou/z/FxZZ6e/lnRUf3/fnn+HtN9/zDv2Bwb6e0s6Me33SWVjmozraz9WApVszelp6E5kvxg7gePS8q3Au9P8U8Bb0/zngH8eYF8fB65P80cBLwOj0zGe7mObG8ha9daQ/cJvS+UXkvVEW0vWa+/LwDSyX92byPosqgEeIutos+d++9v+zrz13gu0AxNSrC+R9QHXDDwANKb1Psm+1tIvAn/bz+d5R97ylLz5LwB/lebvBC5O838JbM07h3+X5muBcb0c45dAa5oP4H+l+a8An+5l/c8Cf1PAOT+bbPxypffuBN7SY19vIOuJN7c8Mb3eB8xN8yeTdQnS37F6/h0uy8UONAALgdl9/b2B+vR3OzFtMx6o62s/lf53NhynXOdhZr1ZFvsGEVoEzJI0gewL41ep/EayL4f+nAZ8AyAinpX0EnAksLnfreDfI+uwcEneL+3TgJsjoousw8VfkfX4uhl4JCKWAyjrcnwW8GAvsfS1fU/3RcSmtL8lwGHARLIvwf9JP4zryb7Qcn40wGfKeZ2kL6T9NQF3p/I3sm8cix8C/5TmHwWuV9a547/HwIM77Sb78ofsb3dWgXH1ds7PTtPjabkJmEuWXHPagTmSvgH8J9lQDE1k1Ws/zrtozO/qvbdj9XQ28Pq8K5kJ6di76f3vvQlYGRGPAkTq7VlSX/tZVtBZsYI5qVh/duXNdwFjKnj811RlDbB+F1An6WTgX1LZ3x/A8bvI/r2I7Bf5xX1ss63Afd8AXBART0p6L9kv7z5FxAPKhjT4Q+AGSVdFxE39bLIn0s/yvNgL0ds5F/D/R8S/9LJ+Lr4Nko4FziG7wnon8DGyMTr6GjK3kL+vyK7i7n5VoXQ6vf99+tLrfqz4fE/F9kv65b4hrw7+z4Ff9bMJwK+BdwFIOhI4FHhukCH8GvjfqY68BXgLWSd4fcX7cOwbuvWOfrbfAowr4PgLgFMlHZE+T2P6TAPpuf9xwMp05fGuHvu/MM1flCuUdBiwOiK+SzZa3wkFHHN/Y+rL3cBf5N07mi7poPwVJDUDNRHxU+DTwAnpKmGZpD9N6yglnv2J6W7gg+k8IelIZb1x9+U5YJqkE9P645R1576/+7FB8pWKDcYlwHfSzeV24H0Akv4SICK+02P9bwPXSFpMdp/mvRGxS6+9j16I28iqiJ4ku2/wtxGxKncD+AC2Xwd0SXqS7CpiQ28bR0RHurK4WftG7fs0WS/W/bkF+K6kj5B1L/5/yEZQ7EivuS/SjwH/JunvgJ+TVedAdiXzCUl7gK3Aewr8vP35D+Anks4H/qqvlSLiF5KOBh5Kf7OtwLt59fgu04HvS8r9UL0yvb6L7G//abIhdW8hO/d9eYpX/x2+Rlat9Vi6Ed9BP8PcRsRuZQ9ffEPZgyU7gDPJEnHB+7HBcy/FZkNIStQ7IiIkXUR20/78SsdlVihfqZgNLW8Avpl+TW8E/qLC8ZjtF1+pmJlZ0fhGvZmZFY2TipmZFY2TipmZFY2TipmZFY2TipmZFY2TipmZFc3/BXtq3fFw32T+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_distribution(sent,tags):\n",
    "    cnt_dict={}\n",
    "    for i in tags:\n",
    "        cnt=0\n",
    "        for j in i:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in cnt_dict):\n",
    "            cnt_dict[cnt]+=1\n",
    "        else:\n",
    "            cnt_dict[cnt]=1\n",
    "    cnt_list=list(cnt_dict.keys())\n",
    "    cnt_list.sort()\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for i in cnt_list:\n",
    "        print(i,\":\",cnt_dict[i])\n",
    "        l1.append(i)\n",
    "        l2.append(cnt_dict[i])\n",
    "    plt.plot(l1,l2)\n",
    "    plt.xlabel(\"no. of non-other tags in the sentence\")\n",
    "    plt.ylabel(\"no. of sentences\")\n",
    "    plt.show()\n",
    "get_data_distribution(sent,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120627\n",
      "120627\n"
     ]
    }
   ],
   "source": [
    "def filter_data(sent,tags,exclude_list):\n",
    "    sent_filter=[]\n",
    "    tags_filter=[]\n",
    "    for i in range(len(tags)):\n",
    "    #     print(tags[i])\n",
    "        cnt=0\n",
    "        for j in tags[i]:\n",
    "            if(j!=\"other\"):\n",
    "                cnt+=1\n",
    "        if(cnt in exclude_list):\n",
    "            continue\n",
    "        if(cnt>=0):\n",
    "            sent_filter.append(sent[i])\n",
    "            tags_filter.append(tags[i])\n",
    "    return sent_filter,tags_filter\n",
    "sent_filter,tags_filter=filter_data(sent,tags,[])\n",
    "print(len(sent_filter))\n",
    "print(len(tags_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_len= 120627\n",
      "new_len= 120627\n"
     ]
    }
   ],
   "source": [
    "sent=sent_filter\n",
    "tags=tags_filter\n",
    "def divide_data_pactise(sent,tags,data_div):\n",
    "    print(\"initial_len=\",len(sent))\n",
    "    sent=sent[:len(sent)//data_div]\n",
    "    tags=tags[:len(tags)//data_div]\n",
    "    return sent,tags\n",
    "sent,tags=divide_data_pactise(sent,tags,data_div)\n",
    "print(\"new_len=\",len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['கவனமாகக்', 'காய்ச்சி', 'குளிரவைக்கும்', 'போது', 'ஒற்றைச்சரிவு', 'படிகம்', 'உற்பத்தியாகி', 'காலியிடங்களை', 'நிரப்புகிறது']\n",
      "['எனினும்', 'இம்மொழிகளில்', 'பல', 'பிரெஞ்சு', 'மொழியின்', 'தாக்கத்தால்', 'வழக்கொழிந்து', 'போயுள்ளன']\n",
      "['இது', 'ஐதராபாத்தின்', 'கிழக்குப்', 'புறநகர்ப்', 'பகுதியான', 'உப்பாலில்', 'அமைந்துள்ளது']\n",
      "['மந்தியூர்', 'ஊராட்சி', ',', 'தமிழ்நாட்டின்', 'திருநெல்வேலி', 'மாவட்டத்தில்', 'உள்ள', 'கடையம்', 'வட்டாரத்தில்', 'அமைந்துள்ளது']\n",
      "['இவர்களில்', 'பெண்கள்', '1492', 'பேரும்', 'ஆண்கள்', '1538', 'பேரும்', 'உள்ளனர்']\n",
      "['இதன்', 'இசையமைப்பாளர்', 'மகேஷ்', 'மாதவன்']\n",
      "['இவர்', 'நடித்த', 'திரைப்படங்களில்', 'கன்னட', 'மொழித்', 'திரைப்படங்களே', 'அதிகமாகும்']\n",
      "['ரெட்பஸ்', 'இன்', 'ஆங்கிலம்']\n",
      "['இவற்றில்', 'இருந்து', '7', 'ஊராட்சி', 'மன்ற', 'உறுப்பினர்களைத்', 'தேர்ந்தெடுக்கின்றனர்']\n",
      "['திண்டுக்கல்', 'வரை', 'தெற்கு', 'தொடர்வண்டிப்', 'பாதையும்', 'இந்த', 'நெடுஞ்சாலைக்கு', 'இணையாக', 'அமைந்துள்ளது']\n"
     ]
    }
   ],
   "source": [
    "for i in sent[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent_len 210\n",
      "avg_sent_len 11.138260920026196\n",
      "max_sent_len_fit 22\n"
     ]
    }
   ],
   "source": [
    "max_sent_len=-1\n",
    "for i in sent:\n",
    "    if(len(i)>max_sent_len):\n",
    "        max_sent_len=len(i)\n",
    "print(\"max_sent_len\",max_sent_len)\n",
    "avg_sent_len=0\n",
    "for i in sent:\n",
    "    avg_sent_len+=len(i)\n",
    "avg_sent_len=avg_sent_len/len(sent)\n",
    "print(\"avg_sent_len\",avg_sent_len)\n",
    "max_len=int(2*(avg_sent_len))\n",
    "print(\"max_sent_len_fit\",max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex.findall(r'\\X', sent[0][0])\n",
    "def separate_into_char(sent):\n",
    "    char=[]\n",
    "    for i in sent:\n",
    "        for j in i:\n",
    "            l=regex.findall(r'\\X',j)\n",
    "            char.append(l)\n",
    "    return char\n",
    "char=separate_into_char(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['க', 'வ', 'ன', 'மா', 'க', 'க்']\n",
      "['கா', 'ய்', 'ச்', 'சி']\n",
      "['கு', 'ளி', 'ர', 'வை', 'க்', 'கு', 'ம்']\n",
      "['போ', 'து']\n",
      "['ஒ', 'ற்', 'றை', 'ச்', 'ச', 'ரி', 'வு']\n",
      "['ப', 'டி', 'க', 'ம்']\n",
      "['உ', 'ற்', 'ப', 'த்', 'தி', 'யா', 'கி']\n",
      "['கா', 'லி', 'யி', 'ட', 'ங்', 'க', 'ளை']\n",
      "['நி', 'ர', 'ப்', 'பு', 'கி', 'ற', 'து']\n",
      "['எ', 'னி', 'னு', 'ம்']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in char[:10]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_size=50\n",
    "word_min_count=1\n",
    "c2v=Word2Vec(char,size=char_embedding_size,min_count=word_min_count)\n",
    "# print(c2v.wv[\"ल\"])\n",
    "# c2v.wv.most_similar(positive=\"ा\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3195"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c2v.wv.most_similar(positive=\"क\")\n",
    "len(c2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3195\n",
      "2396\n"
     ]
    }
   ],
   "source": [
    "tokenizer_char=Tokenizer()\n",
    "tokenizer_char.fit_on_texts(char)\n",
    "char_index=tokenizer_char.word_index\n",
    "print(len(char_index))\n",
    "num_char=(len(char_index)*3)//4\n",
    "print(num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397\n",
      "<UNK_CHAR>\n"
     ]
    }
   ],
   "source": [
    "def add_unk_char(char_index,num_char):\n",
    "    ref={}\n",
    "    for i,j in char_index.items():\n",
    "        if(j<=num_char):\n",
    "            ref[i]=j\n",
    "    ref[\"<UNK_CHAR>\"]=num_char+1\n",
    "    char_index=ref\n",
    "    char_index_rev={}\n",
    "    for (i,j) in char_index.items():\n",
    "        char_index_rev[j]=i\n",
    "    print(char_index[\"<UNK_CHAR>\"])\n",
    "    print(char_index_rev[char_index[\"<UNK_CHAR>\"]])\n",
    "    return char_index,char_index_rev\n",
    "char_index,char_index_rev=add_unk_char(char_index,num_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of chars: 2397\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of chars:\",len(char_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "4.485572446644214\n",
      "max_char_len_fit 8\n"
     ]
    }
   ],
   "source": [
    "max_char_len=-1\n",
    "for i in char:\n",
    "    if(len(i)>max_char_len):\n",
    "        max_char_len=len(i)\n",
    "print(max_char_len)\n",
    "avg_char_len=0\n",
    "for i in char:\n",
    "    avg_char_len+=len(i)\n",
    "avg_char_len=avg_char_len/len(char)\n",
    "print(avg_char_len)\n",
    "max_char_len=int(2*avg_char_len)\n",
    "print(\"max_char_len_fit\",max_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words: 173940\n",
      "No. of tags: 9\n",
      "130455\n"
     ]
    }
   ],
   "source": [
    "tokenizer_sent=Tokenizer()\n",
    "tokenizer_tags=Tokenizer()\n",
    "tokenizer_sent.fit_on_texts(sent)\n",
    "tokenizer_tags.fit_on_texts(tags)\n",
    "word_index_sent=tokenizer_sent.word_index\n",
    "word_index_tags=tokenizer_tags.word_index\n",
    "print(\"No. of words:\",len(word_index_sent))\n",
    "print(\"No. of tags:\",len(word_index_tags))\n",
    "num_words=(len(word_index_sent)*3)//4\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref={}\n",
    "for i,j in word_index_sent.items():\n",
    "    if(j<=num_words):\n",
    "        ref[i]=j\n",
    "ref[\"<UNK_WORD>\"]=num_words+1\n",
    "word_index_sent=ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_rev_sent={}\n",
    "word_index_rev_tags={}\n",
    "for i,j in word_index_sent.items():\n",
    "    word_index_rev_sent[j]=i\n",
    "for i,j in word_index_tags.items():\n",
    "    word_index_rev_tags[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char={}\n",
    "for i,j in word_index_sent.items():\n",
    "#     print(i,j)\n",
    "    l=[]\n",
    "    if(i==\"<UNK_WORD>\"):\n",
    "        l=[char_index[\"<UNK_CHAR>\"]]*max_char_len\n",
    "        word_char[i]=l\n",
    "#         print(l)\n",
    "        continue\n",
    "    for k in regex.findall(r'\\X',i):\n",
    "        if(k in char_index):\n",
    "#             print(k,end=\"-\")\n",
    "            h=char_index[k]\n",
    "        else:\n",
    "#             print(k)\n",
    "            h=char_index[\"<UNK_CHAR>\"]\n",
    "#         else:\n",
    "#             print(i)\n",
    "#             print(k,end=\"-\")\n",
    "#             h=char_index[\"<UNK_CHAR>\"]\n",
    "#             print(\"********\")\n",
    "#             print(\"------------------------------\")\n",
    "#             #         print(h)\n",
    "        l.append(h)\n",
    "    word_char[i]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char.items():\n",
    "#     print(i)\n",
    "# print(word_char[\"<UNK_WORD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in word_char.items():\n",
    "    word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130456\n",
      "('கழி', array([  1, 112,   0,   0,   0,   0,   0,   0], dtype=int32))\n",
      "('விக்சனரி', array([42,  4, 52, 26, 44,  0,  0,  0], dtype=int32))\n",
      "('தப்பவிட்ட', array([11, 14, 13, 42,  6, 18,  0,  0], dtype=int32))\n",
      "('நடிப்பதற்காக', array([71, 34, 14, 13, 11, 36, 48,  1], dtype=int32))\n",
      "('ஹன்னிபாஸ்', array([186,   3,  90,  55,  97,   0,   0,   0], dtype=int32))\n",
      "('போர்க்லம்', array([83,  5,  4, 41,  2,  0,  0,  0], dtype=int32))\n",
      "('எகிப்துடன்', array([51, 33, 14,  9, 18,  3,  0,  0], dtype=int32))\n",
      "('மன்னராட்சி்', array([  23,    3,   26,   37,    6, 1067,    0,    0], dtype=int32))\n",
      "('தற்காலிக', array([11, 36, 48, 77,  1,  0,  0,  0], dtype=int32))\n",
      "('ஒடேஸா', array([ 72, 179, 270,   0,   0,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_char={}\n",
    "# for i,j in word_index_sent.items():\n",
    "#     l=[]\n",
    "#     for k in regex.findall(r'\\X',i):\n",
    "#         if(k in char_index):\n",
    "#             l.append(char_index[k])\n",
    "#         else:\n",
    "#             l.append(char_index[\"<UNK_CHAR>\"])\n",
    "#     word_char[i]=l\n",
    "# for i,j in word_char.items():\n",
    "#     word_char[i]=pad_sequences([j],maxlen=max_char_len,padding=\"post\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130456\n",
      "('கழி', array([  1, 112,   0,   0,   0,   0,   0,   0], dtype=int32))\n",
      "('விக்சனரி', array([42,  4, 52, 26, 44,  0,  0,  0], dtype=int32))\n",
      "('தப்பவிட்ட', array([11, 14, 13, 42,  6, 18,  0,  0], dtype=int32))\n",
      "('நடிப்பதற்காக', array([71, 34, 14, 13, 11, 36, 48,  1], dtype=int32))\n",
      "('ஹன்னிபாஸ்', array([186,   3,  90,  55,  97,   0,   0,   0], dtype=int32))\n",
      "('போர்க்லம்', array([83,  5,  4, 41,  2,  0,  0,  0], dtype=int32))\n",
      "('எகிப்துடன்', array([51, 33, 14,  9, 18,  3,  0,  0], dtype=int32))\n",
      "('மன்னராட்சி்', array([  23,    3,   26,   37,    6, 1067,    0,    0], dtype=int32))\n",
      "('தற்காலிக', array([11, 36, 48, 77,  1,  0,  0,  0], dtype=int32))\n",
      "('ஒடேஸா', array([ 72, 179, 270,   0,   0,   0,   0,   0], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(len(word_char))\n",
    "counter=0\n",
    "for i in word_char.items():\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if(counter==10):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_int={}\n",
    "for i,j in word_char.items():\n",
    "    word_char_int[word_index_sent[i]]=j\n",
    "# for i in word_char_int.items():\n",
    "#     print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_embedding_matrix=np.zeros((len(word_char) + 1, max_char_len))\n",
    "for i,j in word_char_int.items():\n",
    "    word_char_embedding_matrix[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in word_char_embedding_matrix:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130457, 50)\n"
     ]
    }
   ],
   "source": [
    "char_embedding_matrix = np.zeros((len(word_char) + 1, char_embedding_size))\n",
    "for i,j in char_index_rev.items():\n",
    "    if(j in c2v.wv.vocab):\n",
    "        char_embedding_matrix[i]=c2v.wv[j]\n",
    "print(char_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in char_embedding_matrix:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_int=[]\n",
    "for i in word_char_int.items():\n",
    "    char_int.append(i[1])\n",
    "# print(char_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datenum': 6,\n",
       " 'event': 9,\n",
       " 'location': 2,\n",
       " 'name': 3,\n",
       " 'number': 4,\n",
       " 'occupation': 5,\n",
       " 'organization': 7,\n",
       " 'other': 1,\n",
       " 'things': 8}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK_WORD>\n"
     ]
    }
   ],
   "source": [
    "# word_char[\"<UNK_WORD>\"]#array([2389, 2389, 2389, 2389, 2389], dtype=int32)\n",
    "# word_index_sent[\"<UNK_WORD>\"]#2389\n",
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j==\"<UNK_WORD>\"):\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int=[]\n",
    "for i in sent:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    sent_int.append(l)\n",
    "tags_int=[]\n",
    "for i in tags:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        l.append(word_index_tags[j])\n",
    "    tags_int.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_int_padded=pad_sequences(sent_int,maxlen=max_len,padding='post')\n",
    "tags_int_padded=pad_sequences(tags_int,maxlen=max_len,padding=\"post\")\n",
    "# for i in tags_int_padded:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=100\n",
    "workers=5\n",
    "window_size=5\n",
    "word_min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sent:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130457, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v=Word2Vec(sent,size=embedding_size,workers=workers,window=window_size,min_count=word_min_count)\n",
    "embedding_matrix = np.zeros((len(word_index_sent) + 1, embedding_size))\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.76805449e+00 -1.56304085e+00 -2.85098791e+00 ... -2.09451580e+00\n",
      "   6.10754490e-01 -2.89812803e-01]\n",
      " [-5.11842072e-01  3.67344570e+00 -3.36386061e+00 ... -3.13530779e+00\n",
      "   5.53837419e-01  2.78794551e+00]\n",
      " ...\n",
      " [-3.15769413e-03  6.44868985e-03 -3.99376964e-03 ... -1.22380126e-02\n",
      "   5.18245273e-04  6.80109207e-03]\n",
      " [ 1.44852197e-03  6.56643417e-03 -9.08188708e-03 ... -1.01369442e-02\n",
      "   1.16634415e-02 -2.48159422e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for i,j in word_index_rev_sent.items():\n",
    "    if(j in w2v.wv.vocab):\n",
    "        embedding_matrix[i]=w2v.wv[j]\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('location', 2)\n",
      "('things', 8)\n",
      "('datenum', 6)\n",
      "('other', 1)\n",
      "('name', 3)\n",
      "('event', 9)\n",
      "('number', 4)\n",
      "('occupation', 5)\n",
      "('organization', 7)\n",
      "{'location': array([0., 1., 0., 0., 0., 0., 0., 0., 0.]), 'things': array([0., 0., 0., 0., 0., 0., 0., 1., 0.]), 'datenum': array([0., 0., 0., 0., 0., 1., 0., 0., 0.]), 'other': array([1., 0., 0., 0., 0., 0., 0., 0., 0.]), 'occupation': array([0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'event': array([0., 0., 0., 0., 0., 0., 0., 0., 1.]), 'number': array([0., 0., 0., 1., 0., 0., 0., 0., 0.]), 'name': array([0., 0., 1., 0., 0., 0., 0., 0., 0.]), 'organization': array([0., 0., 0., 0., 0., 0., 1., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "tag_dir={}\n",
    "for i in word_index_tags.items():\n",
    "    print(i)\n",
    "    tag_dir[i[0]]=np.eye(len(word_index_rev_tags))[i[1]-1]\n",
    "print(tag_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120627, 22)\n"
     ]
    }
   ],
   "source": [
    "print(tags_int_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=[]\n",
    "count=0\n",
    "for i in tags_int_padded:\n",
    "    l=[]\n",
    "    for j in i:\n",
    "#         print(j,end=\"____\")\n",
    "        if(j==0):\n",
    "            l.append(tag_dir[\"other\"])\n",
    "        else:\n",
    "            l.append(tag_dir[word_index_rev_tags[j]])\n",
    "    l=np.array(l)\n",
    "#     print(l.shape)\n",
    "#     print(count)\n",
    "    count+=1\n",
    "    tags_vec.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120627, 22)\n",
      "(120627, 22)\n",
      "(120627, 22, 9)\n",
      "['கவனமாகக்', 'காய்ச்சி', 'குளிரவைக்கும்', 'போது', 'ஒற்றைச்சரிவு', 'படிகம்', 'உற்பத்தியாகி', 'காலியிடங்களை', 'நிரப்புகிறது']\n",
      "['other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other']\n"
     ]
    }
   ],
   "source": [
    "print(sent_int_padded.shape)\n",
    "print(tags_int_padded.shape)\n",
    "print(np.array(tags_vec).shape)\n",
    "print(sent[0])\n",
    "\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vec=np.array(tags_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units=300\n",
    "from keras.layers import Embedding,InputLayer,Conv1D,MaxPooling1D,Input,Flatten,concatenate,merge,Reshape,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0=Input(shape=(max_len,))\n",
    "emb0=Embedding(len(word_index_sent)+1,max_char_len,weights=[word_char_embedding_matrix],trainable=False,input_length=max_len)(inputs0)\n",
    "emb01=TimeDistributed(Embedding(len(word_char)+1,char_embedding_size,weights=[char_embedding_matrix],trainable=False,input_length=max_char_len))(emb0)\n",
    "conv0=TimeDistributed(Conv1D(filters=20,kernel_size=5,padding=\"same\",activation=\"relu\"))(emb01)\n",
    "conv01=TimeDistributed(Conv1D(filters=11,kernel_size=5,padding=\"same\",activation=\"relu\"))(conv0)\n",
    "maxpool0=TimeDistributed(MaxPooling1D(pool_size=max_char_len))(conv01)\n",
    "# dropout0=TimeDistributed(Dropout(0.25))(maxpool0)\n",
    "newdim = tuple([x for x in maxpool0.shape.as_list() if x != 1 and x is not None])\n",
    "reshape0= Reshape(newdim) (maxpool0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_1/Reshape_1:0\", shape=(?, 22, 8, 50), dtype=float32)\n",
      "Tensor(\"time_distributed_2/Reshape_2:0\", shape=(?, 22, 8, 20), dtype=float32)\n",
      "Tensor(\"time_distributed_3/Reshape_2:0\", shape=(?, 22, 8, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(emb01)\n",
    "print(conv0)\n",
    "print(conv01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input(shape=(max_len,))\n",
    "emb1=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs1)          \n",
    "concat_0_1=concatenate([emb1,reshape0],axis=-1)\n",
    "conv1=Conv1D(filters=15,kernel_size=5,padding=\"same\",activation=\"relu\")(concat_0_1)\n",
    "# dropout1=Dropout(0.25)(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2=Input(shape=(max_len,))\n",
    "emb2=Embedding(len(word_index_sent)+1,embedding_size,weights=[embedding_matrix],trainable=False,input_length=max_len)(inputs2)\n",
    "concat_1_2=concatenate([emb2,conv1],axis=-1)\n",
    "layers=Bidirectional(LSTM(units=num_hidden_units,input_shape=(max_len,embedding_size),return_sequences=True))(concat_1_2)\n",
    "# dropout2=Dropout(0.25)(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(100))(layers)\n",
    "layers=TimeDistributed(Dense(len(word_index_tags),activation=\"softmax\"))(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inputs0,inputs1,inputs2],outputs=layers)\n",
    "model.compile(optimizer=\"adam\",metrics=[\"mae\",\"acc\"],loss=\"categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test=train_test_split(sent_int_padded,tags_vec,test_size=0.3,random_state=1)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "x_train=sent_int_padded\n",
    "y_train=tags_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 22, 8)        1043656     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 22, 8, 50)    6522850     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 22, 8, 20)    5020        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 22, 8, 11)    1111        time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 22, 1, 11)    0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 22, 100)      13045700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 22, 11)       0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 22, 111)      0           embedding_3[0][0]                \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 22, 100)      13045700    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 22, 15)       8340        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 22, 115)      0           embedding_4[0][0]                \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 22, 600)      998400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 22, 100)      60100       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 22, 100)      10100       time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 22, 9)        909         time_distributed_6[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 34,741,886\n",
      "Trainable params: 7,606,830\n",
      "Non-trainable params: 27,135,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png',show_shapes=True,show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "(None, 22)\n",
      "(None, 22)\n",
      "--------------------\n",
      "embedding_1\n",
      "(None, 22)\n",
      "(None, 22, 8)\n",
      "--------------------\n",
      "time_distributed_1\n",
      "(None, 22, 8)\n",
      "(None, 22, 8, 50)\n",
      "--------------------\n",
      "time_distributed_2\n",
      "(None, 22, 8, 50)\n",
      "(None, 22, 8, 20)\n",
      "--------------------\n",
      "time_distributed_3\n",
      "(None, 22, 8, 20)\n",
      "(None, 22, 8, 11)\n",
      "--------------------\n",
      "input_2\n",
      "(None, 22)\n",
      "(None, 22)\n",
      "--------------------\n",
      "time_distributed_4\n",
      "(None, 22, 8, 11)\n",
      "(None, 22, 1, 11)\n",
      "--------------------\n",
      "embedding_3\n",
      "(None, 22)\n",
      "(None, 22, 100)\n",
      "--------------------\n",
      "reshape_1\n",
      "(None, 22, 1, 11)\n",
      "(None, 22, 11)\n",
      "--------------------\n",
      "input_3\n",
      "(None, 22)\n",
      "(None, 22)\n",
      "--------------------\n",
      "concatenate_1\n",
      "[(None, 22, 100), (None, 22, 11)]\n",
      "(None, 22, 111)\n",
      "--------------------\n",
      "embedding_4\n",
      "(None, 22)\n",
      "(None, 22, 100)\n",
      "--------------------\n",
      "conv1d_3\n",
      "(None, 22, 111)\n",
      "(None, 22, 15)\n",
      "--------------------\n",
      "concatenate_2\n",
      "[(None, 22, 100), (None, 22, 15)]\n",
      "(None, 22, 115)\n",
      "--------------------\n",
      "bidirectional_1\n",
      "(None, 22, 115)\n",
      "(None, 22, 600)\n",
      "--------------------\n",
      "time_distributed_5\n",
      "(None, 22, 600)\n",
      "(None, 22, 100)\n",
      "--------------------\n",
      "time_distributed_6\n",
      "(None, 22, 100)\n",
      "(None, 22, 100)\n",
      "--------------------\n",
      "time_distributed_7\n",
      "(None, 22, 100)\n",
      "(None, 22, 9)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    print(i.name)\n",
    "    print(i.input_shape)\n",
    "    print(i.output_shape)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in y_train:\n",
    "# #     print(i)\n",
    "#     print(len(i))\n",
    "#     print(\"------------------\")\n",
    "len(char_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in x_train[:1000]:\n",
    "#     for j in i:\n",
    "#         if(j==0):\n",
    "#             break\n",
    "#         print(word_index_rev_sent[j],end=\"/\")\n",
    "#         l=[]\n",
    "#         for k in word_char_int[j]:\n",
    "#             if(k==0):\n",
    "#                 break\n",
    "#             l.append(char_index_rev[k])\n",
    "#         print(\"\".join(l),end=\" \")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################TO BE UNCOMMENTED FOR TRAINING#############################\n",
    "# epochs=10\n",
    "# prev_loss=1\n",
    "# loss_increase_warning=0\n",
    "# # for i in range(epochs):\n",
    "# his=model.fit(x=[x_train,x_train,x_train],y=y_train,validation_split=0.2,epochs=25, batch_size=10,callbacks=[\n",
    "#     EarlyStopping(monitor=\"val_loss\",mode=\"auto\",patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model_hindi_safe.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model_hindi_safe.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################TO BE UNCOMMENTED FOR TRAINING#############################\n",
    "# model.save(\"ner_tamil_safe_final_complete_training.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for keyword argument 'data_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-a2935fe26046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### to predict load the new model along with the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ner_tamil_safe_final_complete_training.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2523\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 2511\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   2512\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         layer = deserialize_layer(config.pop('layer'),\n\u001b[0;32m--> 110\u001b[0;31m                                   custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m                                                            list(custom_objects.items())))\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \"\"\"\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for keyword argument 'data_format'"
     ]
    }
   ],
   "source": [
    "##### to predict load the new model along with the weights\n",
    "from keras.models import load_model\n",
    "model = load_model('./ner_tamil_safe_final_complete_training.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate([x_test,x_test,x_test],y_test)==model2.evaluate([x_test,x_test,x_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ans=model.predict([x_test,x_test,x_test])\n",
    "# c_other=0\n",
    "# i_other=0\n",
    "# c_non=0\n",
    "# i_non=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### to predict load the new model along with the weights\n",
    "# from keras.models import load_model\n",
    "# model = load_model('ner_kannada_safe_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in padded_x_test:\n",
    "    if(len(i)!=max_len):\n",
    "        print(i)\n",
    "# padded_x_test=np.array(padded_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "incorrect=0\n",
    "for i in range(len(my_ans)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(pre_y_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j,k in zip(my_ans[i],pre_y_test[i]):\n",
    "        if(j==k):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "#     print(\"-----------------------------------------------------------------\")\n",
    "print(\"accuracy=\",(correct)/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=np.zeros(shape=(len(word_index_rev_tags),len(word_index_rev_tags)),dtype=\"int32\")\n",
    "for i,j in zip(my_ans,pre_y_test):\n",
    "#     print(i)\n",
    "#     print(j)\n",
    "#     print(\"----------------\")\n",
    "    for ii,jj in zip(i,j):\n",
    "        x=word_index_tags[ii]\n",
    "        y=word_index_tags[jj]\n",
    "#         print(x,y)\n",
    "        confusion_matrix[x-1][y-1]+=1\n",
    "#         for i in confusion_matrix:\n",
    "#             print(i)\n",
    "#         print(\"-------------------\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word_index_rev_tags)):\n",
    "    print(word_index_rev_tags[i+1])\n",
    "    row_sum=0\n",
    "    col_sum=0\n",
    "    for j in range(len(word_index_rev_tags)):\n",
    "        row_sum+=confusion_matrix[i][j]\n",
    "        col_sum+=confusion_matrix[j][i]\n",
    "    p=confusion_matrix[i][i]/row_sum\n",
    "    r=confusion_matrix[i][i]/col_sum\n",
    "    f1=(2*p*r)/(p+r)\n",
    "    print(\"precision=\",p)\n",
    "    print(\"recall=\",r)\n",
    "    print(\"f1 score=\",f1)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_other=0\n",
    "i_other=0\n",
    "c_non=0\n",
    "i_non=0\n",
    "for i,j in zip(pre_y_test,my_ans):\n",
    "#     print(i,j)\n",
    "    for ii,jj in zip(i,j):\n",
    "#         print(x,y)\n",
    "        x=ii\n",
    "        y=jj\n",
    "        if(x==y):\n",
    "            if(x==\"other\"):\n",
    "                c_other+=1\n",
    "            else:\n",
    "                c_non+=1\n",
    "        elif(x!=y):\n",
    "            if(x==\"other\"):\n",
    "                i_other+=1\n",
    "            else:\n",
    "                i_non+=1\n",
    "#other accuracy\n",
    "print(\"other accuracy\")\n",
    "print(\"correct\",c_other)\n",
    "print(\"incorrect\",i_other)\n",
    "print(c_other/(c_other+i_other))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"non other accuracy\")\n",
    "print(\"correct\",c_non)\n",
    "print(\"incorrect\",i_non)\n",
    "print(c_non/(c_non+i_non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################final testing########################\n",
    "data_div=1\n",
    "pre_x_test=[]\n",
    "with codecs.open(\"v1_test2.ta\",\"r\",encoding=\"utf-8\") as f:\n",
    "    l1=[]\n",
    "    for i in f:\n",
    "        i=i.strip()\n",
    "        if(i==\"newline\"):\n",
    "            pre_x_test.append(l1)\n",
    "#             print(len(pre_x_test))\n",
    "            l1=[]\n",
    "        else:\n",
    "            l1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test\n",
    "# y_test\n",
    "pre_x_test_int=[]\n",
    "for i in pre_x_test:\n",
    "#     print(i)\n",
    "    l=[]\n",
    "    for j in i:\n",
    "        if(j in word_index_sent):\n",
    "            l.append(word_index_sent[j])\n",
    "        else:\n",
    "            l.append(word_index_sent[\"<UNK_WORD>\"])\n",
    "    pre_x_test_int.append(l)\n",
    "padded_x_test=pad_sequences(pre_x_test_int,maxlen=max_len,padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict([padded_x_test,padded_x_test,padded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans=[]\n",
    "for i in range(len(ans)):\n",
    "#     print(len(ans[i]))\n",
    "#     print(len(pre_x_test[i]))\n",
    "    l=[]\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        if(j<len(ans[i])):\n",
    "#             print(np.argmax(ans[i][j]),end=\"_\")\n",
    "            l.append(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "#             printprint(len(pre_x_test))\n",
    "# print(len(pre_y_test))\n",
    "# print(len(my_ans))(word_index_rev_tags[np.argmax(ans[i][j])+1])\n",
    "        else:\n",
    "            l.append(\"other\")\n",
    "#             print(0,end=\"_\")\n",
    "#     print(l)\n",
    "    my_ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl=open(\"q2.ta\",\"w\")\n",
    "for i in range(len(pre_x_test)):\n",
    "#     print(pre_x_test[i])\n",
    "#     print(my_ans[i])\n",
    "    for j in range(len(pre_x_test[i])):\n",
    "        fl.write(my_ans[i][j]+\"\\n\")\n",
    "    fl.write(\"newline\\n\")\n",
    "#     print(\"---------------------\")\n",
    "fl.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
